{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c834b3e2",
   "metadata": {},
   "source": [
    "__NLP__ - Natural Language Processing обработка естественного языка - область знаний на стыке  информатики, лингвистики и искусственного интеллекта, направленная на изучение методов анализа и синтеза естественного языка."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8a317b",
   "metadata": {},
   "source": [
    "__Библиотека NLTK__ — пакет библиотек и программ для символьной и статистической обработки\n",
    "естественного языка, написанных на языке программирования Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75810529",
   "metadata": {},
   "source": [
    "__Токены__ - текстовые единицы, на которые разбивается текст на естественном языке: символы, слова, словосочетания, предложения, абзацы и т.д. Чаще всего разбивают на слова."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540bbc49",
   "metadata": {},
   "source": [
    "Токены образуют __словарь__, который может быть отсортирован по алфавиту."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3714b17",
   "metadata": {},
   "source": [
    "__Документ__ - это совокупность токенов, которые принадлежат одной смыловой единице. В качестве документа может выступать предложение, комментарий или пост пользователя."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175f67c2",
   "metadata": {},
   "source": [
    "__Корпус__ - это генеральная совокупность всех документов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ff3a15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06f99b22",
   "metadata": {},
   "source": [
    "### Предобработка текста"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a598809",
   "metadata": {},
   "source": [
    "1. Перевод всех букв в тексте в нижний регистр\n",
    "2. Удаление пунктуации и пробельных символов\n",
    "3. Токенизация по словам\n",
    "4. Удаление стоп слов\n",
    "5. Стемминг\n",
    "6. Лемматизация\n",
    "7. Векторизация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfbf7c1",
   "metadata": {},
   "source": [
    "__Токенизация__ (иногда – сегментация) по словам – это процесс разделения предложений на слова-компоненты"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9462ca",
   "metadata": {},
   "source": [
    "__Cтемминг__ (от англ. stemming) — это поиск основы слова, учитывающий морфологию исходного слова.\n",
    "Стемминг выполняет морфологический разбор слова, находит общую для всех его грамматических\n",
    "форм основу, отсекая суффиксы и окончания."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d135a7",
   "metadata": {},
   "source": [
    "__Лемматизация.__ Данный подход является альтернативой стемминга. Основная идея в приведении слова к словарной\n",
    "форме — лемме. \n",
    "Например для русского языка:\n",
    "\n",
    "для существительных — именительный падеж, единственное число;\n",
    "\n",
    "для прилагательных — именительный падеж, единственное число, мужской род;\n",
    "\n",
    "для глаголов, причастий, деепричастий — глагол в инфинитиве несовершенного вида.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9152b0",
   "metadata": {},
   "source": [
    "Одна из основных библиотек для обработки естественного языка - pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad258e07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "535e85b1",
   "metadata": {},
   "source": [
    "Векторное представление - сопоставление словам и фразам из некоторого словаря численных векторов, длина которых значительно меньше количества слов в словаре.\n",
    "\n",
    "__Векторизация__ - это процесс кодирования текста в виде целых чисел, то есть числовой формы для\n",
    "создания векторов признаков, чтобы алгоритмы машинного обучения могли понимать наши данные."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442322cc",
   "metadata": {},
   "source": [
    "### Векторизация. Прямое кодирование"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4c5b24",
   "metadata": {},
   "source": [
    "__Прямое кодирование (one-hot encoding)__ - самый простой способ преобразования токенов в тензоры (координатное представление вектора) и выполняется следующим способом:\n",
    "- каждый токен представляет бинарный вектор (значения 0 или 1)\n",
    "- единица ставится тому элементу, который соответствует номеру токена в словаре\n",
    "\n",
    "Проблемой прямого кодирования является размерность\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefa8207",
   "metadata": {},
   "source": [
    "### Векторизация. Мешок слов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076f0c24",
   "metadata": {},
   "source": [
    "Модель мешка слов (Bag of Words, BoW) - для документа формируется вектор размерности словаря и записывается признак насколько часто слово встречается в нем. Этот метод не учитывает важность того или иного токена."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f595e48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a6ee4422",
   "metadata": {},
   "source": [
    "### Векторизация. TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c84fce",
   "metadata": {},
   "source": [
    "TF-IDF (TF - Term Frequency - как часто слово встречается в документе (важность слова в контексте документа), IDF - Inverce Document Frequency) - статистическая мера, используемая для оценки важности слова в контексте документа, являющегося частью коллекции документов или корпуса. Вес некоторого слова пропорционален частоте употребления этого слова в документе и обратно пропорционален частоте употребления слова во всех документах коллекции (важность слова возрастает, если он используется в одном документе и не используется в других)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f874ec88",
   "metadata": {},
   "source": [
    "TF считается для токенов документа, IDF - токенов всего корпуса. В TF-IDF редкие слова и слова, которые встречаются во всех документах, несут мало информации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab6d3a4",
   "metadata": {},
   "source": [
    "### Вложение слов (Words Embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e1929a",
   "metadata": {},
   "source": [
    "Вложение слов - это методика моделирования языка, используемая для отображения слов на векторы действительных чисел. Это тип представления слов, который позволяет словам с близким значением иметь сходное представление."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074d35f2",
   "metadata": {},
   "source": [
    "Слова или фразы представляются в векторном пространстве с несколькими измерениями и могут генерироваться с использованием различных методов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a868045e",
   "metadata": {},
   "source": [
    "###  Векторизация. Word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd08024",
   "metadata": {},
   "source": [
    "Word2vec - технология от компании Google, которая заточена на статистическую обработку больших массивов текстовой информации."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32097616",
   "metadata": {},
   "source": [
    "Реализованы два основных алгоритма обучения:\n",
    "- CBoW (Continuonus Bag of Words, \"непрерывный мешок со словами\") архитектурное решение, которое предсказывает текущее слово, исходя из окружающего его контекста.\n",
    "- Skip-gram, подход, действующий наоборот: использует текущее слово, чтобы предугадать окружающте его слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61b5cc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
