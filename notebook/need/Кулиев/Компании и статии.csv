,name,name_company,date,note,description,activity,rating
0,Вселенная существовала и до Большого взрыва. У нас есть подтверждение,FirstVDS,"2023-03-30, 10:44","Это только часть паззлаВ течение многих десятилетий ученые описывали начало нашей Вселенной, смешивая горячий Большой взрыв с сингулярностью. Мол, «Большой взрыв» был моментом рождения пространства и времени. Однако в начале 1980-х годов появилась новая теория, называемая космической инфляцией. Она предположила, что до горячего Большого взрыва Вселенная всё-таки существовала и вела себя совсем по-другому. В 2018 году у нас наконец появились очень веские доказательства того, что Большой взрыв не был моментом начала всего, как мы считали ранее. Большой взрыв и точка сингулярностиНаши представления о Большом взрыве как о теоретическом «старте Вселенной» насчитывают почти 100 лет. В 1924 году Эдвард Хаббл измерил расстояние до ближайших спиральных туманностей и вдруг неожиданно для себя обнаружил, что это на самом деле галактики и они удаляются от нас и друг от друга. До этого почти все были уверены, что Вселенная сжимается — следуя теориям Эйнштейна и учитывая наличие сил гравитации.В 1931 году Жорж Леметр предположил, что если учесть очевидное расширение Вселенной и спроецировать его назад во времени, то это означает, что чем дальше в прошлое, тем меньше была Вселенная. Тогда, возможно, был какой-то момент, когда вся масса Вселенной была сосредоточена в одной точке, в «первобытном атоме», где и возникла современная ткань времени и пространства.В то время это была просто философская теория. Мол, если сегодня Вселенная расширяется и остывает, значит, раньше она была меньше, плотнее и горячее. Но в 1968 и 1970 годах группа ученых, включая Стивена Хокинга, опубликовала статьи, показывающие, что математическая сингулярность является неизбежным начальным условием для релятивистских моделей Большого взрыва. То есть, чтобы формулы работали, нужно принять, что вся материя и энергия Вселенной когда-то были сконцентрированы в одной точке.Поскольку достаточно мощной технологии (телескопов и коллайдеров) для проверки всех теорий тогда у нас не было, эти математические модели стали лучшим объяснением принципов появления нашей Вселенной. Люди тогда даже не думали, что можно получить информацию напрямую из источника. В конце концов, большая часть наших знаний о черных дырах тоже извлечена напрямую из формул математики.В результате несколько десятилетий эти два представления о Большом взрыве — как о горячем плотном состоянии, описывающем раннюю Вселенную, и о начальной точке сингулярности — были неразделимы. Это была одна вещь.Но постепенно ученые приходят к тому, что Вселенная какое-то время существовала и до общеизвестного «горячего» Большого взрыва. Ему предшествовало другое, инфляционное состояние. То есть то, что было до Большого взрыва, тоже расширялось и даже, может быть, имело свою прото-энергию.Всё это происходило больше 13,8 млрд лет назад, и казалось бы, такие нюансы должны быть потеряны для нас навсегда. Но на самом деле при нынешнем уровне технологий это можно проверить. Различия между Вселенной, начавшейся с горячего Большого взрыва, и Вселенной, в которой сначала шла инфляционная фаза, предшествовавшая Большому взрыву и создавшая его, почти неуловимы, но они существуют.Традиционная картинка «горячего» Большого взрываВ чём вообще разница между двумя моделями? Ну, как минимум мы понимаем, что при «горячем» Большом взрыве, который мы экстраполировали бы вплоть до сингулярности, Вселенная достигла бы максимально возможных температур и энергий. Такой этап существования нашей Вселенной называют «Планковской эпохой», которая длилась бы 10−43 секунд. В таком случае размер Вселенной составлял бы меньше 10−35 м («Планковский радиус»), она имела бы температуру примерно 1032 К («Планковская температура») и плотность около 1093 г/см³ («Планковская плотность»). Более плотным и более горячим не может быть ничего — это была бы уже другая Вселенная, с другими законами физики.То есть, если бы мы могли показать, что температуры или плотности были значительно меньше (или несоизмеримо больше) — эта теория была бы разрушена. В конце концов, она основывается на математических выкладках, а реальные физические доказательства всегда первостепенны.К сожалению, из нашего времени мы никак не можем точно увидеть эти параметры. Только посчитать их. Поэтому прямых доказательств (или опровержений) теории «Большой взрыв = сингулярность» у нас здесь нет.Но есть и другой путь. Даже если Вселенная имела когда-то такие «средние» плотность и температуру, в ней, как мы знаем, были несовершенства: как сверхплотные, так и недостаточно плотные области. По мере того как она расширялась и охлаждалась, эти сверхплотные области из-за гравитации притягивали к себе всё больше материи и энергии, увеличиваясь со временем, в то время как недостаточно плотные области, наоборот, отдавали свою материю и энергию в более плотные окружающие их структуры. Так создавались семена будущей космической паутины.Только из-за наличия этих несовершенств образовались звезды и галактики, и только из-за них мы существуем сегодня. Их существованию есть сотни подтверждений, но в доказательствах они, по сути, и не нуждаются: в полностью «равномерной» Вселенной не родилось бы столько гигантских и разнообразных структур, и не существовали бы мы.Вселенная не просто равномерно расширяется, но имеет внутри себя крошечные несовершенства плотности, которые с течением времени позволяют формировать планеты, звезды, галактики и скопления галактик. Добавление неоднородностей плотности поверх однородного фона — отправная точка для понимания того, как выглядит и работает наша Вселенная.Детали, которые появляются в современной космической паутине, определились гораздо раньше. «Зёрна» современных крупномасштабных структур были заложены там, в самой ранней Вселенной. Сегодняшние звезды, туманности и скопления галактик можно проследить до первых маленьких несовершенств плотности, возникших тогда, когда первые атомы впервые сформировались во Вселенной. Эта связь вызвана гравитацией и тем фактом, что по Общей теории относительности концентрация материи и энергии определяет кривизну пространства.Эти древние семена, хоть и плохо, но остаются видимы сегодня — в виде маленьких температурных несовершенств в космосе вокруг нас. Где-то космос чуть «теплее» (там больше материи), где-то чуть холоднее. Это так называемый космический микроволновой фон — остаточное сияние Большого взрыва, впервые обнаруженное в 1965 году. Температуры этого сияния находятся в пределе 2,72548 ± 0,00057 Kельвина, то есть это практически абсолютный ноль. Но оно всё-таки есть. Фоновое излучениеМы все живём на этом фоне. Просто он настолько слабый (ещё бы, 13,8 млрд лет прошло!), что заметить его могут только наши самые совершенные аппараты. А когда ученые впервые его засекли, то даже не поняли, что происходит: они думали, что у них барахлит оборудование. Но в общем да, если вас учили в школе, что в глубоком космосе — абсолютный ноль, то это неправда. Из-за всё еще остающегося после Большого взрыва излучения температура космоса составляет почти три Кельвина. Хотя она постепенно снижается, так что ещё через несколько миллиардов лет новым цивилизациям потребуются куда более мощные приборы, чтобы её обнаружить. А дальше — тайны начала Вселенной станут окончательно покрыты мраком.Но пока что наши устройства, если их точно настроить, могут наблюдать этот реликтовый фон, потому что свет должен пройти из дальних областей пространства, в которых он возникает, к «глазам» наблюдателя. А это означает, что:сверхплотные области с большим количеством материи и энергии, чем в среднем, будут казаться более холодными, поскольку свет должен «выбраться» из более крупного гравитационного потенциала;области с пониженной плотностью, с меньшим количеством материи и энергии, будут казаться более горячими, чем в среднем, поскольку свету будет проще дойти до нас;области средней плотности и гравитационного потенциала будут иметь среднюю температуру космического микроволнового фона.Эти температурные несовершенства, которые мы наблюдаем в остаточном сиянии Большого взрыва, пришли к нам из эпохи, которая наступила через 380 000 лет после «запуска» Вселенной — когда первичная плазма охладела настолько, что электроны и протоны смогли начать образовывать атомы водорода. Это событие впервые сделало Вселенную почти прозрачной для излучения — потому что свет больше не рассеивался, сталкиваясь с морем свободных электронов.К сожалению, более ранние этапы существования нашей Вселенной мы наблюдать не можем: там просто нечего было наблюдать. Но даже отпечаток Вселенной через 380 000 лет после её основания представляет собой достаточно большой набор данных, который можно анализировать.Когда мы видим горячую или холодную точку в реликтовом излучении, эта разница температур обычно соответствует области пониженной или повышенной плотности во время появления реликтового излучения через 380 000 лет после Большого взрыва. Это следствие эффекта Сакса-ВульфаОткуда вообще возникли эти несовершенства? Почему Вселенная не единообразна во всех направлениях? История тут совершенно разная, в зависимости от того, какого варианта «начала всего» вы придерживаетесь:Согласно «сингулярной» теории Большого взрыва, Вселенная просто «родилась» с исходным набором несовершенств. Потом эти несовершенства росли и развивались по законам гравитационного коллапса и взаимодействия частиц, в том числе взаимодействия между нормальной и темной материей.Если принять инфляционную теорию происхождения Вселенной, где горячий Большой взрыв возник только после какого-то периода космического расширения, тогда эти несовершенства посеяны квантовыми флуктуациями. То есть флуктуациями, возникающими даже в пустом пространстве из-за принципа неопределенности энергии и времени, присущего квантовой механике. То есть наша Вселенная не была случайно рождена «неравномерной»: если пространство и время появились до Взрыва, то ни в каком другом виде она и не могла существовать.Второй вариант объяснения дает нам важную зацепку. Если эта теория верна, то получается, квантовые флуктуации, существовавшие до Большого взрыва, каким-то образом отображены в нём. За прошедшие миллиарды лет эти маленькие отблески растянулись до гигантских масштабов за счет расширения Вселенной. А более поздние флуктуации растянулись уже поверх них.Отсюда идёт важный вывод. Если что-то существовало до взрыва, оно должно быть самым большим, самым «растянутым». В теории, даже больше горизонта самой нашей Вселенной — которая расширяется как результат того самого взрыва. Мы должны быть способны заметить результаты в масштабах, превышающих космический горизонт: так называемые флуктуации сверхгоризонта. Если они существуют — значит, сам Большой взрыв не мог быть началом всего.Квантовые флуктуации, возникающие во время инфляции, накладываются друг на друга, поэтому выявить более старые и более масштабные может быть очень непросто. Нужны очень точные приборы, результатам которых мы можем доверятьЕщё раз. В «сингулярной» картине Большого взрыва, где всё было сжато в одну точку и он был началом всего, результаты флуктуаций, которые мы ожидаем увидеть, будут ограничены скоростью света (+ расстоянием, на которое за это время успел расшириться космос). Если же до взрыва что-то существовало, то «мазки на картине», теоретически могут быть больше. Намного больше (если это «что-то» существовало ощутимое время и было достаточно крупным). Или всего на несколько процентов больше (если время и пространство до Большого взрыва было невелико).Это, конечно, было бы очень сложно заметить. Флуктуации, которые могли произойти за несколько сотен долей секунды до взрыва, уже растянуты до масштаба большего, чем наблюдаемая в настоящее время Вселенная. А более поздние флуктуации накладываются на более ранние, засоряя сигнал. Но мы хотя бы понимаем методику: если что-то существовало до Большого Взрыва, мы можем начать поиск сверхмасштабных флуктуаций, которых не должно было бы быть, если бы Вселенная началась с сингулярности.Остаточное свечение Большого взрыва, реликтовое излучение, имеет крошечные несовершенства: колебания температуры величиной в несколько сотен микрокельвинов. Эти флуктуации были вызваны комбинацией процессов, но в том числе и неоднородностьюВ общем, большой тест, который можно провести, состоит в том, чтобы исследовать Вселенную и искать либо наличие, либо отсутствие этих флуктуаций сверхгоризонта. Существует предел тому, как далеко мог пройти сигнал, который двигался со скоростью света. И нам нужно понять, когда он был испущен.Масштабы меньше горизонта Вселенной зависят от физики, которая возникла с момента начала горячего Большого взрыва.Масштабы, равные горизонту, являются верхним пределом того, на что могли повлиять физические сигналы с момента начала горячего Большого взрыва.Масштабы, превышающие горизонт, известные как масштабы сверхгоризонта, выходят за пределы того, что могло быть вызвано физическими сигналами, генерируемыми во время или после Большого взрыва.Изнутри нашей Вселенной заметить эти широкие «мазки» на нашем уровне технологий — достаточно сложно. Но, к счастью, наблюдение за температурой космического микроволнового фона — это не единственный способ получить информацию. Мы также можем посмотреть на поляризацию света от этого фона. Поляризация светаДальше будет очень научно, но вкратце смысл такой: мы смотрим на то же реликтовое излучение (другой информации нет), но не на его температуру, а на его поляризацию — насколько электромагнитные волны, дошедшие к нам с тех времен, структурированы в том или ином плане. Это позволяет говорить о структурах, существовавших там, где эти волны прошли.Когда свет проходит через Вселенную, он взаимодействует с материей внутри нее — в частности, с электронами. Если свет поляризуется радиально-симметричным образом, это пример поляризации вектора Е (электрического). Если свет поляризован по часовой стрелке или против часовой стрелки, то это пример поляризации вектора B (магнитного).И здесь можно провести корреляционный анализ: между поляризацией света, который мы ловим, и температурными флуктуациями космического микроволнового фона. Сопоставить их в тех же угловых масштабах. Это позволит нам отсечь лишний шум и заметить остаточные последствия самых больших флуктуаций. И понять, какой сценарий мы наблюдаем: «сингулярный Большой взрыв без инфляции» или «инфляционное состояние, которое и привело к горячему Большому взрыву».На этой карте показан сигнал поляризации реликтового излучения, полученный спутником Планка в 2015 годуКак их отличить, эти два сценария основания Вселенной, глядя на поляризацию, если супер-технически:Hidden textВ обоих случаях мы ожидаем увидеть субгоризонтные корреляции (как положительные, так и отрицательные) между поляризацией вектора Е в космическом микроволновом фоне и температурными флуктуациями в его пределах. Это вполне очевидно: если на пути света есть материя, в которой находятся электроны, то там будет и поляризация, и нехарактерная для остального фона температура.В обоих случаях мы ожидаем, что в масштабе космического горизонта (на данный момент соответствующего угловым масштабам около 1 градуса и мультипольному моменту около l = 200-220) эти корреляции будут равны нулю.Однако в масштабах сверхгоризонта сценарий «сингулярного Большого взрыва» будет иметь только один большой положительный «всплеск» корреляции между поляризацией Е-моды и температурными флуктуациями космического микроволнового фона — это тот момент, когда звезды начали формироваться в больших количествах и стали реионизировать межгалактическую среду. С другой стороны, сценарий «инфляционного Большого взрыва» обязан содержать этот всплеск, но также должен показать ряд отрицательных корреляций между поляризацией Е-моды и температурными флуктуациями в масштабах сверхгоризонта (в угловых масштабах между 1 и 5 градусами, мультипольные моменты от l = 30 до l = 200). Это продемонстрировало бы, что что-то существовало до взрыва и оставило следы, не зависящие от него. Характерные «мазки» в масштабах, даже превышающих размеры реликтового излучения.Эта публикация команды спутника WMAP 2003 года является самой первой научной статьей, в которой представлены доказательства сверхгоризонтных флуктуаций в спектре корреляции температуры и поляризации (так называемой «взаимной корреляции TE»). Точки — это реальные показатели корреляции. Тот факт, что слева от зеленой пунктирной линии (т.е. в масштабах сверхгоризонта) корреляция выходит отрицательной — сложно не заметить. Это значит, что помимо материи, образовавшейся после Большого взрыва, на поляризацию реликтового излучения влияет что-то ещеПо этому самому первому графику, опубликованному командой телескопа WMAP в 2003 году (ровно 20 лет назад!), видно то, что космологи называют «спектром взаимной корреляции TE»: корреляции между поляризацией E-моды и флуктуациями температуры космического микроволнового фона.Как мы можем видеть, в субгоризонтных масштабах (справа от зеленой линии) присутствуют как положительные, так и отрицательные корреляции. Но в сверхгоризонтных масштабах (слева от линии) отчетливо виден большой «провал» — значительная зона отрицательной корреляции. Это согласуется с прогнозом теории инфляции (сплошная линия). И категорически не согласуется с теорией сингулярности Большого взрыва (пунктирная линия).Конечно, это было 20 лет назад, и с тех пор наши технологии продвинулись вперед. Спутник WMAP был заменен спутником Планка, который превосходил его почти по всем параметрам. Он видел Вселенную в большем количестве диапазонов длин волн, мог опускаться до меньших угловых масштабов, лучше считывал нюансы температуры, включал в себя специальный поляриметрический прибор и чаще брал снимки неба, что еще больше уменьшало вероятность ошибок.И когда мы смотрим на окончательные (2018 года) данные кросс-корреляции TE от команды Планка, результаты захватывают дух. Всё предельно очевидно:Если кто-то хочет увидеть недвусмысленное свидетельство сверхгоризонтных флуктуаций, ему достаточно посмотреть на показатели «взаимной корреляции TE» (поляризации и температуры) от спутника Планка. В диапазоне сверхгоризонта (слева от зеленой линии) виден очень четкий, очень характерный «провал». После того, как в 2018 году ученые его увидели, доказательства в пользу существования сверхгоризонтных флуктуаций стали неопровержимы.ВыводыКак мы можем ясно видеть по данным спутников, не остается никаких сомнений в том, что во Вселенной точно существуют сверхгоризонтные флуктуации. А это значит, что неинфляционная сингулярная модель Большого взрыва, которая считалась общепринятой почти 100 лет, не согласуется со Вселенной, которую мы наблюдаем. Вместо этого мы видим, что горячему Большому взрыву должно было предшествовать инфляционное состояние. Которое, правда, длилось не очень долго — судя по размеру флуктуаций и степени их влияния на современный космос.Наша Вселенная существовала и до Большого взрыва, вероятно — краткую долю секунды. В ней, скорее всего, еще не было атомов, но уже происходили квантовые процессы, вызвавшие неравномерности распределения энергии. А уже после этого случился Взрыв.И русская, и английская Википедия сейчас довольно обтекаемо касаются этого момента. Так что у читателей, которые привыкли, что Большой взрыв = сингулярность, это мнение не нарушается. А зря.Есть и другие тесты на наличие «довзрывной» инфляции, которые можно было бы провести. Оценить масштабно-инвариантный спектр чисто адиабатических флуктуаций, проверить ограничение максимальной температуры горячего Большого взрыва, найти небольшое отклонение от идеальной плоскостности в космологической кривизне, проверить спектр «первобытных» гравитационных волн, постоянно доносящихся к нам с того времени. И так далее. Тем не менее тест на наличие флуктуаций сверхгоризонта достаточно прост и надежен. И уже проведен. Если остальные эксперименты когда-нибудь осуществят — то только для того, чтобы подтвердить уже известное: пространство и время существовали и до Большого взрыва.Это лучшая из имеющихся у нас картин того, как ведет себя вся Вселенная, где инфляция предшествует Большому взрыву и вызывает его.Как всё это выглядело, в каком формате оно существовало, как долго? Не ясно. Но по крайней мере это точно была уже наша Вселенная: в ней работали известные нам законы квантовой физики, и их последствия видны на звездном небе, если хорошо присмотреться.А дальше — пространство для новых открытий и новых теорий. Потому что теперь мы знаем, что Большой Взрыв, оказывается, не был началом всего.",Виртуальные и выделенные серверы в ДЦ в Москве,  Научно-популярное Системное администрированиеЧитальный залИнформационная безопасностьIT-инфраструктура,398.02
1,44 совета по Ansible: рекомендации и Best Practices,Southbridge,"2023-03-30, 09:57","Ansible — один из наиболее часто используемых программных инструментов с открытым исходным кодом для управления конфигурацией, предоставления программного обеспечения и развертывания приложений в облачных и локальных средах. В этой статье мы поделимся Practices по настройке Ansible, предложим интересные подходы для эффективной работы с внутренними компонентами продукта.Базовые Best PracticesВыбирайте YAML вместо JSON: Хотя Ansible позволяет использовать синтаксис JSON, с YAML читать файлы и проекты гораздо легче.Используйте одинаковые пробелы: Чтобы красиво разделить объекты и улучшить читаемость, оставьте пустую строку между блоками, задачами или другими компонентами.Используйте последовательную стратегию тегирования: Тегирование — это мощная функция в Ansible, поскольку она позволяет группировать задачи и детальнее ими управлять. Теги дают нам возможность добавлять тонкие элементы управления выполнением задач.Добавляйте комментарии: Если вы считаете, что это необходимо, не стесняйтесь использовать комментарии, объясняющие цель и причину возникновения задач, переменных и так далее.Используйте стратегию с последовательным именованием: Прежде, чем приступить к настройке своих проектов в Ansible, подумайте о применении последовательной стратегии именования для задач, плейбуков, переменных, ролей и модулей.Определите руководство по стилю: Следуйте букве руководства — оно поможет последовательно выполнять задачи. Если вы ищете вдохновение, посмотрите на это руководство по стилю от OpenShift.Будьте проще: Ansible предоставляет множество опций и расширенных возможностей, но это не значит, что мы должны использовать их все в один момент времени. Найдите те инструменты Ansible, которые подходят для вашего случая, и попытайтесь максимально упростите свой проект. Например, начните с простого плейбука и файла инвентаризации, а более сложные инструменты или рефакторинг добавьте позже.Храните свои проекты в системе контроля версий (VCS): Сохраняйте файлы Ansible в репозитории кода и регулярно фиксируйте новые изменения.Не храните конфиденциальные значения в обычном тексте: Для секретов и конфиденциальных значений используйте Ansible Vault для шифрования переменных и файлов и защиты любой конфиденциальной информации.Тестируйте проекты: Используйте инструменты типа Ansible Lint и добавляйте этапы тестирования в конвейеры CI/CD для ваших репозиториев Ansible. Для тестирования ролей Ansible рекомендуем взглянуть на Molecule. Для тестирования вводимых данных или проверки пользовательских выражений можно использовать модуль assert.Организуйте каталогиПосмотрите, как выглядит хорошо организованная структура каталогов Ansible:inventory/   production        # inventory file for production servers   staging          # inventory file for staging environment   testing          # inventory file for testing environment  group_vars/  group1.yml       # variables for particular groups  group2.yml host_vars/  host1.yml        # variables for particular systems  host2.yml  library/         # Store here any custom modules (optional) module_utils/       # Store here any custom module_utils to support modules (optional) filter_plugins/      # Store here any filter plugins (optional)  master.yml        # master playbook webservers.yml      # playbook for webserver tier dbservers.yml       # playbook for dbserver tier  roles/  example_role/        # this hierarchy represents a ""role""    tasks/      #      main.yml   # <-- tasks file can include smaller files if warranted    handlers/     #      main.yml   # <-- handlers file    templates/    # <-- files for use with the template resource      ntp.conf.j2  # <------- templates end in jinja2    files/      #      bar.txt    # <-- files for use with the copy resource      foo.sh    # <-- script files for use with the script resource    vars/       #      main.yml   # <-- variables associated with this role    defaults/     #      main.yml   # <-- default lower priority variables for this role    meta/       #      main.yml   # <-- role dependencies    library/     # roles can also include custom modules    module_utils/   # roles can also include custom module_utils    lookup_plugins/  # or other types of plugins, like lookup in this case   monitoring/       # same kind of structure as ""common"" was above, done for the monitoring roleBest Practices инвентаризации Best PracticesИспользуйте группы инвентаризации: Группируйте узлы на основе общих атрибутов, которые они могут разделять — расположение, цель, роли, среда.Делайте отдельную инвентаризацию для каждой среды: Определите отдельный файл инвентаризации для каждой среды — производственной, промежуточной, тестовой и так далее, чтобы изолировать их друг от друга и избежать ошибок, связанных с неправильным выбором среды.Проводите динамическую инвентаризацию: При работе с облачными провайдерами или быстро меняющимися средами ведение статических инвентаризаций может стать сложной задачей. Используйте динамическую группировку во время работы: Мы можем создавать динамические группы с помощью модуля `group_by` на основе заданного атрибута — к примеру, на основе их операционной системы — и выполнять различные задачи на каждом из них без определения таких групп в инвентаризации.- name: Gather facts from all hosts  hosts: all  tasks:   - name: Classify hosts depending on their OS distribution    group_by:     key: OS_{{ ansible_facts['distribution'] }}  # Only for the Ubuntu hosts - hosts: OS_Ubuntu  tasks:   - # tasks that only happen on Ubuntu go here   # Only for the CentOS hosts - hosts: OS_CentOS  tasks:   - # tasks that only happen on CentOS go hereBest Practices для плейбуков и сценариевВсегда указывайте статус задач: Чтобы сделать ваши задачи более понятными, задавайте параметр state, даже если это не требуется из-за значения по умолчанию.Размещайте каждый аргумент задачи в отдельной строке: Это помогает сделать файлы Ansible более удобными для чтения. Рассмотрим несколько примеров:Это рабочий, но плохо читаемый вариант:- name: Add the user {{ username }}  ansible.builtin.user: name={{ username }} state=present uid=999999 generate_ssh_key=yes  become: yesВместо этого вы можете использовать данный синтаксис: он улучшает читабельность и понятность задач и их аргументов:- name: Add the user {{ username }}  ansible.builtin.user:   name: ""{{ username }}""   state: present   uid: 999999   generate_ssh_key: yes  become: yesИспользуйте плейбуки верхнего уровня для оркестровки плейбуков нижнего уровня: Вы можете логически сгруппировать задачи, сценарии и роли в низкоуровневых плейбуках и использовать плейбуки верхнего уровня для требуемой вам оркестровки. Группируйте задачи с помощью блочного синтаксиса: Задачи, которые связаны друг с другом и имеют общие атрибуты или теги, могут быть сгруппированы с помощью функции blok. Еще одним преимуществом этой опции является более простой задач, находящихся в одном блоке.- name: Install, configure, and start an Nginx web server  block:   - name: Update and upgrade apt    ansible.builtin.apt:     update_cache: yes     cache_valid_time: 3600     upgrade: yes    - name: ""Install Nginx""    ansible.builtin.apt:     name: nginx     state: present    - name: Copy the Nginx configuration file to the host    template:     src: templates/nginx.conf.j2     dest: /etc/nginx/sites-available/default       - name: Create link to the new config to enable it    file:     dest: /etc/nginx/sites-enabled/default     src: /etc/nginx/sites-available/default     state: link    - name: Create Nginx directory    ansible.builtin.file:     path: /home/ubuntu/nginx     state: directory    - name: Copy index.html to the Nginx directory    copy:     src: files/index.html     dest: /home/ubuntu/nginx/index.html    notify: Restart the Nginx service  when: ansible_facts['distribution'] == 'Ubuntu'  tags: nginx  become: true  become_user: rootИспользуйте контроллеры для запущенных задач: Контроллеры позволяют выполнить задачу после внесенных изменений. Контроллер будет запущен, когда произойдут изменения в файле index.html из приведенного выше примера.handlers:  - name: Restart the Nginx service   service:    name: nginx    state: restarted   become: true   become_user: rootBest Practices для переменныхПеременные позволяют пользователям параметризовать различные компоненты Ansible и хранить значения, которые мы можем повторно использовать. Всегда задавайте значения по умолчанию для ваших переменных: Установите значения по умолчанию для всех групп в group_vars/all. Для каждой роли установите переменные по умолчанию в roles/<role_name>/defaults.main.yml.Используйте каталоги groups_vars и host_vars: Чтобы файл инвентаризации был максимально аккуратным и лаконичным,  устанавливайте переменные групп и хостов в каталогах groups_vars и host_vars.Ссылайтесь на роль в переменных в качестве префикса: Старайтесь быть четкими при определении имен переменных для ролей. nginx_port: 80 apache_port: 8080Best Practices для модулейХраните локальные модули рядом с плейбуками: Используйте каталог ./library каждого проекта Ansible для хранения соответствующих пользовательских модулей. Плейбуки, которые имеют каталог ./library относительно своего пути, могут напрямую ссылаться на любые модули внутри него.Не используйте модули command и shell: Рекомендуем использовать их только тогда, когда нет другого выбора. Вместо этого выбирайте специализированные модули, которые обеспечивают отказоустойчивость и необходимую обработку ошибок.Указывайте аргументы модуля, когда это имеет смысл: Во многих аргументах модулей значения по умолчанию могут быть опущены. Для удобства можно указать некоторые из этих аргументов, например, для определения статуса плейбука.Отдавайте предпочтение многозадачности в модуле, а не циклам: Наиболее эффективным способом определения списка однотипных задач типа установки пакетов является использование нескольких задач в одном модуле.- name: Install Docker dependencies  ansible.builtin.apt:   name:    - curl    - ca-certificates    - gnupg    - lsb-release   state: latestДокументируйте и тестируйте пользовательские модули: Каждый пользовательский модуль должен содержать примеры, записанные настройки и описание полученных ответов. Новые модули следует тщательно тестировать перед выпуском. Вы можете создать плейбуки для тестирования пользовательских модулей и проверки различных сценариев для тестов.Best Practices для ролейСледуйте структуре каталога ролей Ansible Galaxy: Используйте команду ansible-galaxy init <role_name> для создания стандартного каталога ролей.Сохраняйте назначение ролей: Каждая роль должна иметь отдельную ответственность и отдельную функциональность. Разделяйте роли на основе различных функциональных возможностей или технических областей задач.Ограничивайте зависимости между ролями: Избегая большого количества зависимостей в ваших ролях, вы поддерживать их слабосвязанными, разрабатывать их независимо друг от друга и использовать их без заморочек со сложными зависимостями между ними.Отдавайте предпочтение модулям import_role или include_role: Чтобы лучше контролировать порядок выполнения ролей и задач, используйте модули import_role или include_role, а не классические роли.Будьте осторожны в отношении Ansible Galaxy Roles: При загрузке и использовании содержимого и ролей из Galaxy проверяйте содержимое файлов и выбирайте роли от надежных авторов.Храните используемые роли Galaxy локально: Чтобы не зависеть от внешнего репозитория Ansible Galaxy, вы можете хранить любые роли из Galaxy в своих репозиториях кода и управлять ими как частью проекта.Best Practices для развертывания средыСначала протестируйте изменения в staging: Это отличный способ убедиться в том, что изменения приведут к ожидаемому результату, а не к новым проблемам.Ограничьте выполнение задач заданными узлами: Если вы хотите запустить плейбук на определенном хосте, вы можете использовать флаг --limit. Если вам нужно запустить только определенные задачи из плейбука на основе тегов, вы можете определить, какие теги будут выполняться, с помощью флага --tags.Проверьте, какие задачи будут запущены перед выполнением: Вы можете использовать флаг --list-tasks для подтверждения того, какие задачи будут запущены без их фактического выполнения. Вы можете использовать флаг --list-hosts: так вы убедитесь в том, на какие хосты повлияет плейбук, но при этом не запустить его.Убедитесь в том, что вы собрались менять, но при этом не запускайте обновления: Используйте флаг --check для прогнозирования изменений, которые могут произойти. Объедините его с флагом --diff, чтобы показать различия в измененных файлах.Начните с конкретной задачи: Используйте флаг --start-at-task, чтобы плейбук начал работать с выбранной вами задачи.Используйте Rolling Updates для контроля количества целевых машин: По умолчанию Ansible пытается запустить программу параллельно на всех хостах. Чтобы добиться непрерывных обновлений, вы можете использовать ключевое слово serial. Используя это ключевое слово, вы можете определить, на скольких хостах изменения могут выполняться параллельно.Управляйте стратегией выполнения (запуска) playbook: По умолчанию Ansible завершает выполнение каждой задачи на всех хостах перед переходом к следующей задаче. Если вы хотите выбрать другую стратегию выполнения, ознакомьтесь с этой документацией. От редакцииС инструментами Ansible мы подробно знакомимся на курсе DevOps Upgrade — интенсивном курсе для тех, кто хочет стать DevOps-инженером. Поток стартует с практическими заданиями и поддержкой от спикеров курса стартует уже 15 мая — узнать подробнее о программе и присоединиться к группе вы можете на нашем сайте. ",Обеспечиваем стабильную работу highload-проектов,  IT-инфраструктура DevOpsСистемное администрированиеКарьера в IT-индустрииПрограммирование,272.35
2,Файловая система BTRFS,OTUS,"2023-03-29, 17:03","Некоторое время назад мной была представлена статья, посвященная дисковой подсистеме ОС Linux и среди прочих в комментариях к данной статье предлагалось рассмотреть работу с кэшем в файловой системе BTRFS. В этой статье я предлагаю вернуться к теме файловых систем в Linux и для начала посмотреть что из себя представляет BTRFS, где применяется и как с ней лучше работать. Данная статья предназначена для администраторов Линукс, имеющих практический опыт администрирования данной ОС.Итак, файловая система BTRFS (B-Tree Filesystem) предназначена для работы в Unix-подобных операционных системах. Она была разработана компанией Oracle в 2007 году. BTRFS построена по принципу CoW (Copy on Write), то есть при чтении области данных используется общая копия, в случае изменения данных — создается новая копия. Данная технология используется для оптимизации многих процессов, происходящих в операционной системе. Немного о деревьяхВ BTRFS как и в других ФС все данные хранятся на диске по определенным адресам, которые в свою очередь сохранены в метаданных. Однако, здесь все данные организуются в B-деревья (те самые B-tree, которые присутствуют в названии ФС). Не вдаваясь в дебри математических наук, которыми многих из нас мучали в вузе, кратко поясню принцип поиска в таких деревьях.При поиске B-Tree мы должны выбирать пути из нескольких вариантов. То есть, если мы ищем в дереве например, значение 30, как представлено на картинке ниже, то при обходе мы сначала проверим ключ в корне, 13 меньше 30, значит нам надо перейти на правого потомка, 17<30, 24<30, значит снова переходим на правого потомка и здесь находим нужное значение. Какое все это имеет отношение к работе файловой системы? B-Tree  в отличии от двоичных деревьев позволяет хранить много ключей в одном узле и при этом может ссылаться на несколько дочерних узлов. Это значительно уменьшает высоту дерева и, соответственно, обеспечивает более быстрый доступ к диску. Но вернемся к BTRFS.Основные характеристикиПрежде всего, как положено при описании какой-либо технологии или решения, приведу основные характеристики BTRFS. Максимальный размер файла в данной ФС может составлять 2^64 байт или 16 экзабайт. При этом в BTRFS также реализована компактная упаковка небольших файлов и индексированные каталоги с экономией места. Для сжатия используются алгоритмы ZLIB, LZO, ZSTD, а также эвристика. Контрольные суммы для данных и метаданных вычисляются с помощью алгоритмов crc32c, xxhash, sha256, blake2b.Ну а кроме этого, в BTRFS есть также динамическое распределение индексов, моментальные снимки с возможностью записи, снимки только для чтения и вложенные тома (отдельные корни внутренней файловой системы). Далее мы более подробно поговорим об этих технологиях и начнем с работы со снимками.Снимки в файловой системеПри работе с файлами, в частности, при операции перезаписи данных, они по факту не перезаписываются, а та часть данных, которая подверглась модификации копируется на новое место.  Затем просто обновляются метаданные о расположении изменившейся информации. Благодаря такому решению мы можем создавать мгновенные снимки файловой системы, которые не занимают места на диске, пока не было внесено много изменений. Ну а если старый блок больше не нужен, потому что он не является частью какого-либо снимка, то мы можем его автоматически удалить.Работа с дискамиКак мы уже упомянули ранее BTRFS может работать с файлами до 16 Экзабайт. Хотя текущая реализация VFS Linux (виртуальной файловой системы,  т.е. промежуточного слоя абстракции) имеет ограничение ядра до 8 Экзабайт. Но даже это уже огромный объем для работы с которым нужны соответствующие носители и BTRFS умеет эффективно работать с такими носителями. Большинство файловых систем используют диск целиком, от начала и до конца для записи своей структуры. Но BTRFS работает с дисками по-другому: независимо от размеров диска, мы делим его на блоки по 1 Гб для данных и 256 Мб для метаданных. Из этих блоков формируются группы, причем, каждая из которых может храниться на разных устройствах. При этом, количество таких блоков в группе может зависеть от уровня RAID для данной группы.  Для управления блоками и группами используется специальное средство – менеджер томов, который уже интегрирован в файловую систему.И еще одна небольшая плюшка. BTRFS при работе с небольшими файлами (по умолчанию до 8К) хранит их непосредственно в метаданных, тем самым снижая накладные расходы и уменьшая фрагментацию диска. Таким образом, наличие большого количества маленьких файлов, как минимум, не приведет к существенной просадке производительности.Думаю, теории для этой статьи достаточно и сейчас самое время перейти к практике, а именно создать файловый раздел. В своем примере я буду по традиции использовать Ubuntu 22.04, однако другие современные дистрибутивы также должны поддерживать BTRFSРазворачиваем BTRFSТрадиционно, процесс установки какого-либо ПО под Linux начинается с обновления пакетов:sudo apt updateДалее в случае с Ubuntu 22.04 у меня поддержка ФС уже есть. Но в случае ее отсутствия необходимо было бы выполнить:sudo apt install btrfs-progs -yДалее нам потребуется неразмеченный диск. Посмотрим что у нас есть с помощью команды:sudo lsblk -e7В моем примере я буду работать с sdb размером 10 Гб.Так как мы будем мучать sdb, то укажем его в параметрах утилиты cfdisk:sudo cfdisk /dev/sdbПосле запуска утилиты выбираем gpt.Далее все достаточно стандартно: выбираем Free space. Так как я планирую использовать весь диск, то соответственно указываем использование всех 10 G. Если у вас планируется использовать только часть дискового пространства, тогда необходимо указать нужный размер. При этом можно использовать следующие сокращения для единиц измерения: M – мегабайты, G – гигабайты, T – терабайты.Для сохранения изменений не забудьте нажать Write.Теперь нам необходимо отформатировать созданный раздел в BTRFS.sudo mkfs.btrfs -L data /dev/sdbВ результате мы получили полную информацию об отформатированном диске. Теперь подмонтируем BTRFS раздел. Для этого сначала создаем точку монтирования. В моем случае это каталог /btrfs. А затем подмонтируем sdb к этому разделу.sudo mkdir -v /btrfssudo mount /dev/sdb /btrfsИ для того, чтобы убедиться в корректности выполненных операций, воспользуемся уже знакомой нам командой:sudo lsblk -e7Статистика использованияПоговорим немного о том, как можно смотреть различную статистику использования BTRFS дисков. Прежде всего воспользуемся командой:sudo btrfs filesystem usage /dataВывод команды содержит различные значения. Посмотрим что означает каждое из них. В первой строке у нас идет общий размер диска – 10 Гб. Далее мы видим объем дискового пространства, зарезервированного для хранения данных и еще неиспользуемого пространства, которого естественно намного больше, так как пока на диск записано немного данных – сколько именно мы видим из значения поля Used. Отрадно, что значение Device missing равно 0.Далее указаны методы (single или DUMP), которые используются для выделения дискового пространства для данных, метаданных и системных данных. При использовании single ФС хранит только одну копию данных, никакой дупликации не используется. Но при использовании DUP файловая система Btrfs выделит для одних и тех же данных дисковое пространство в разных частях файловой системы. Таким образом, в файловой системе будет храниться несколько копий (обычно две) одних и тех же данных.Как можно видеть из рисунка выше, обычные данные у нас распределены в single режиме, а вот метаданные и системные данные используют DUP.ЗаключениеВ этой статье мы начали рассмотрение файловой системы BTRFS. Поговорили об основных преимуществах этой ФС и рассмотрели создание раздела под управлением BTRFS. В заключении хотелось бы заметить, что в сети можно встретить негативные отзывы об использовании данной ФС. Однако, все эти отзывы датированы началом 2010-х годов, когда система еще не была стабильна и могли происходить сбои. Но сейчас эта ФС поддерживается многими операционными системами, ее спецификация уже много лет не изменяется и ее можно использовать без опасения потерять свои данные.В следующей статье мы продолжим рассмотрение BTRFS, и в частности поговорим об использовании нескольких дисков и создании отказоустойчивых конфигураций.Также я хочу порекомендовать вам бесплатный урок от моих коллег из OTUS, которые расскажут, как можно собрать кастомную версию Nginx из исходников. Вы добавите нестандартные модули и библиотеки: модуль brotli, поддержку HTTP/3, библиотеку BogingSSL, RTMP-модуль. А также подготовите окружение и соберёте deb-пакет для установки в систему.Зарегистрироваться на бесплатный урок",Цифровые навыки от ведущих экспертов,  Программирование JavaМашинное обучениеТестирование веб-сервисовPython,832.56
3,Миграция PostgreSQL с DBaaS на дроплет Digital Ocean,OTUS,"2023-03-29, 16:03","Недавно один из наших клиентов обратился к нам с одной интересной задачей: ему нужно было перенести весь свой кластер PostgreSQL с DBaaS (Database as a Service) на дроплет в рамках DigitalOcean. Причиной их перехода с DBaaS на дроплеты была их более низкая стоимость. Эта задача оказалась довольно сложной, поскольку в документации DigitalOcean четко сказано, что “в настоящее время мы не поддерживаем миграцию баз данных из одних кластеров DigitalOcean в другие кластеры в рамках DigitalOcean”.Короче говоря, нам нужно было переносить базу данных своими силами, и мы предоставили клиенту два варианта решения этой задачи:pg_dumpЛогическая репликацияМетод с pg_dump предполагает определенный период простоя, так как мы должны создать дамп, а затем восстановить его на новом сервере. Логическая репликация же оставляет исходную базу данных в рабочем состоянии пока данные копируются в новую базу данных. Как только мы достигнем желаемого состояния, мы можем переключиться на новую базу данных.Для миграции с помощью логической репликации все таблицы, которые необходимо реплицировать, должны иметь первичный или уникальный ключ.Предварительные требования для миграцииЧтобы перенести существующую базу данных в кластер базы данных DigitalOcean, нам необходимо убедиться, что в исходной базе данных включена логическая репликация, получить учетные данные для подключения к исходной базы данных и отключить или обновить любые файрволы между базами данных.Получить Root-права: Для подготовки базы данных к миграции и для проведения самой миграции нам нужны root-права в исходной базе данных.Сделать базу данных общедоступной: Для миграции базы данных имя хоста или IP-адрес исходной базы данных должны быть доступны из публичного интернета. Информация о публичном подключении к базам данных DigitalOcean находится в разделе “Connection Details” на панели управления базой данных.Разрешить удаленные подключения: Во-первых, убедитесь, что база данных разрешает все удаленные подключения. Это определяется переменной базы данных listen_addresses, которая разрешает все удаленные подключения, если ее значение равно. Чтобы проверить ее текущее значение, выполните в терминале PostgreSQL (psql) следующий запрос:SHOW listen_addresses; If enabled, the command line returns: listen_addresses ----------- * (1 row)Если ваш результат будет другим, вы можете разрешить удаленные подключения в вашей базе данных, выполнив следующий запрос:ALTER SYSTEM SET listen_addresses = '*';Мы также должны изменить ваше локальное IPv4-соединение, чтобы разрешить все входящие IP-адреса. Для этого вам нужно найти файл конфигурации pg_hba.conf с помощью следующего запросом:SHOW hba_file;Откройте pg_hba.conf в текстовом редакторе по вашему выбору, например, nano: nano pg_hba.confВ разделе “IPv4 local connections” найдите и замените IP-адрес на 0.0.0.0/0, что разрешат все IPv4-адреса:# TYPE DATABASE USER ADDRESS METHOD  # IPv4 local connections: host all all 0.0.0.0/0 md5 # IPv6 local connections: host all all ::/0 md5Включение логической репликацииУ большинства поставщиков облачных баз данных логическая репликация включена по умолчанию. Логическая репликация может быть не включена, если вы переносите базу данных с локального сервера. Если ваша база данных не подготовлена для логической репликации, то процесс миграции не будет работать, поскольку база данных может перемещать только ваши схемы, а не сами данные.Чтобы убедиться, что логическая репликация включена, выполните следующий запрос в терминале PostgreSQL (psql):show wal_level; If enabled, the output returns: wal_level ----------- logical (1 row) If the output is different, enable logical replication in your database by setting wal_level to logical: ALTER SYSTEM SET wal_level = logical;Изменение максимального количества слотов репликацииПосле включения логической репликации нам нужно убедиться, что значение max_replication_slots вашей базы данных равно или превышает количество баз данных на вашем PostgreSQL сервере. Чтобы проверить текущее значение, выполните следующий запрос в терминале PostgreSQL (psql):show max_replication_slots;Вывод будет выглядеть следующим образом:max_replication_slots ----------- (1 row)Если это значение меньше, чем количество баз данных на нашем PostgreSQL сервере, измените его, выполнив следующий запрос, где use_your_number — это количество баз данных на нашем сервере:ALTER SYSTEM SET max_replication_slots = use_your_number;И перезагрузите сервер.Проблемы, с которыми мы можем столкнуться во время миграцииКогда мы реализуем логическую репликацию без первичного ключа, мы можем столкнуться с некоторыми проблемами. Существует два разных метода реализации логической репликации без столбца с первичным ключом, один из которых — с использованием уникального ключа.Этот метод реализуется с помощью того же самого набора шагов, который мы собираемся здесь выполнить. Его технические аспекты также аналогичны. Просто вместо первичного ключа обновления будут происходить по уникальному ключу.ПредостереженияОн не поддерживает DELETE/UPDATE без репликационного идентификатора.Уникальный индекс нельзя использовать с репликационным идентификатором, если разрешены NULL-значения.Используется REPLICA IDENTITY FULL.Если для репликационного идентификатора не найден подходящий индекс, мы можем установить для него значение FULL. В этом случае все столбцы таблицы коллективно выступают в роли первичного ключа.Из-за дополнительного логирования создается огромное количество WAL.Этот метод может быть медленнее, чем традиционный.Что следует учитыватьИ так, нам нужно установить репликационный идентификатор FULL для таблиц, которые переносятся логически только по UNIQUE ключу, иначе DELETE/UPDATE не будет поддерживаться.После того, как данные из форка DBaaS будут синхронизированы на новую виртуальную машину на дроплете, нам нужно выполнить методы pg_dump и pg_restore для последовательностей. У вас может возникнуть вопрос: зачем нам дамп последовательности и почему мы не можем реплицировать ее с помощью логической репликации?Логическая репликация предназначена отслеживания изменений WAL и информирования подписчиков о текущих состояниях и значениях. Было бы довольно противоречиво реплицировать последовательность, потому что текущее значение последовательности не равно значению, хранящемуся в WAL. Чтобы компенсировать это, документация PostgreSQL предлагает вручную скопировать значения последовательности или использовать для копирования такую ​​утилиту, как pg_dump.Сделайте дамп последовательностей из форка БД DBaaSОстановите форк БД DBaaSВосстановите последовательности на новом дроплетеОтключите логические подпискиНиже приведен краткий обзор того, что было сделано для миграции среды:Исходный кластер: DBasS Digital Ocean Место назначения: дроплеты Digital OceanПроцесс:Клиент выбрал миграцию посредством логической репликации, чтобы сократить время простоя.На целевой виртуальной машине мы установили дистрибутив Percona для PostgreSQL 13.7.Перенесли в место назначения роли из исходного кластера, т.е. DBasS.Сформировали список таблиц, у которых нет первичного ключа, и проинформировал их.Для некоторых таблиц клиент добавил первичный ключ, а для остальных таблиц сформировал уникальный ключ.Установили на виртуальную машину расширения, которые были в исходном кластере.Сформировали дамп схемы из исходного кластера, т.е. DBasS.Восстановили ​​схему на месте назначения, т.е. на дроплетых.Скорректировали в исходном кластере и месте назначения параметры, связанные с логической репликацией, такие как max_replication_slots, max_logical_replication_workers и max_wal_senders.Настроили логическую репликацию, создав публикацию и подписку между исходным кластером и местом назначения.Как только место назначения было синхронизировано, отключили подписчиков.Сформировали дамп последовательностей из исходного кластера и восстановили их в месте назначения.Скорректировали файлы listen_address, pg_hba на месте назначения.Сбросили подписчиков на месте назначения.ЗаключениеКак мы все знаем, PostgreSQL — это объектно-реляционная система управления базами данных с открытым исходным кодом, созданная с упором на расширяемость, скорость и целостность данных. Ее поддержка параллелизма делает ее полностью совместимой с ACID. Мы смогли реализовать миграцию данных клиентов с DBasS на дроплеты, используя одну из замечательных фич PostgreSQL, то есть логическую репликацию. Мы также смогли сформировать дамп последовательностей из исходного кластера и восстановить их на месте назначения.В заключение статьи приглашаем всех желающих на открытое занятие «Автоматизация развертывания на кластера PostgreSQL на базе Patroni в Kubernetes», которое пройдет в рамках онлайн-курса ""PostgreSQL Cloud Solutions"".На этом открытом уроке будет разыграна книга руководителя курса Евгения Аристова — «PostgreSQL 14. Оптимизация, Kubernetes, кластера, облака».Регистрация на открытый урок",Цифровые навыки от ведущих экспертов,  Программирование JavaМашинное обучениеТестирование веб-сервисовPython,832.56
4,Вселенная существовала и до Большого взрыва. У нас есть подтверждение,FirstVDS,"2023-03-30, 10:44","Это только часть паззлаВ течение многих десятилетий ученые описывали начало нашей Вселенной, смешивая горячий Большой взрыв с сингулярностью. Мол, «Большой взрыв» был моментом рождения пространства и времени. Однако в начале 1980-х годов появилась новая теория, называемая космической инфляцией. Она предположила, что до горячего Большого взрыва Вселенная всё-таки существовала и вела себя совсем по-другому. В 2018 году у нас наконец появились очень веские доказательства того, что Большой взрыв не был моментом начала всего, как мы считали ранее. Большой взрыв и точка сингулярностиНаши представления о Большом взрыве как о теоретическом «старте Вселенной» насчитывают почти 100 лет. В 1924 году Эдвард Хаббл измерил расстояние до ближайших спиральных туманностей и вдруг неожиданно для себя обнаружил, что это на самом деле галактики и они удаляются от нас и друг от друга. До этого почти все были уверены, что Вселенная сжимается — следуя теориям Эйнштейна и учитывая наличие сил гравитации.В 1931 году Жорж Леметр предположил, что если учесть очевидное расширение Вселенной и спроецировать его назад во времени, то это означает, что чем дальше в прошлое, тем меньше была Вселенная. Тогда, возможно, был какой-то момент, когда вся масса Вселенной была сосредоточена в одной точке, в «первобытном атоме», где и возникла современная ткань времени и пространства.В то время это была просто философская теория. Мол, если сегодня Вселенная расширяется и остывает, значит, раньше она была меньше, плотнее и горячее. Но в 1968 и 1970 годах группа ученых, включая Стивена Хокинга, опубликовала статьи, показывающие, что математическая сингулярность является неизбежным начальным условием для релятивистских моделей Большого взрыва. То есть, чтобы формулы работали, нужно принять, что вся материя и энергия Вселенной когда-то были сконцентрированы в одной точке.Поскольку достаточно мощной технологии (телескопов и коллайдеров) для проверки всех теорий тогда у нас не было, эти математические модели стали лучшим объяснением принципов появления нашей Вселенной. Люди тогда даже не думали, что можно получить информацию напрямую из источника. В конце концов, большая часть наших знаний о черных дырах тоже извлечена напрямую из формул математики.В результате несколько десятилетий эти два представления о Большом взрыве — как о горячем плотном состоянии, описывающем раннюю Вселенную, и о начальной точке сингулярности — были неразделимы. Это была одна вещь.Но постепенно ученые приходят к тому, что Вселенная какое-то время существовала и до общеизвестного «горячего» Большого взрыва. Ему предшествовало другое, инфляционное состояние. То есть то, что было до Большого взрыва, тоже расширялось и даже, может быть, имело свою прото-энергию.Всё это происходило больше 13,8 млрд лет назад, и казалось бы, такие нюансы должны быть потеряны для нас навсегда. Но на самом деле при нынешнем уровне технологий это можно проверить. Различия между Вселенной, начавшейся с горячего Большого взрыва, и Вселенной, в которой сначала шла инфляционная фаза, предшествовавшая Большому взрыву и создавшая его, почти неуловимы, но они существуют.Традиционная картинка «горячего» Большого взрываВ чём вообще разница между двумя моделями? Ну, как минимум мы понимаем, что при «горячем» Большом взрыве, который мы экстраполировали бы вплоть до сингулярности, Вселенная достигла бы максимально возможных температур и энергий. Такой этап существования нашей Вселенной называют «Планковской эпохой», которая длилась бы 10−43 секунд. В таком случае размер Вселенной составлял бы меньше 10−35 м («Планковский радиус»), она имела бы температуру примерно 1032 К («Планковская температура») и плотность около 1093 г/см³ («Планковская плотность»). Более плотным и более горячим не может быть ничего — это была бы уже другая Вселенная, с другими законами физики.То есть, если бы мы могли показать, что температуры или плотности были значительно меньше (или несоизмеримо больше) — эта теория была бы разрушена. В конце концов, она основывается на математических выкладках, а реальные физические доказательства всегда первостепенны.К сожалению, из нашего времени мы никак не можем точно увидеть эти параметры. Только посчитать их. Поэтому прямых доказательств (или опровержений) теории «Большой взрыв = сингулярность» у нас здесь нет.Но есть и другой путь. Даже если Вселенная имела когда-то такие «средние» плотность и температуру, в ней, как мы знаем, были несовершенства: как сверхплотные, так и недостаточно плотные области. По мере того как она расширялась и охлаждалась, эти сверхплотные области из-за гравитации притягивали к себе всё больше материи и энергии, увеличиваясь со временем, в то время как недостаточно плотные области, наоборот, отдавали свою материю и энергию в более плотные окружающие их структуры. Так создавались семена будущей космической паутины.Только из-за наличия этих несовершенств образовались звезды и галактики, и только из-за них мы существуем сегодня. Их существованию есть сотни подтверждений, но в доказательствах они, по сути, и не нуждаются: в полностью «равномерной» Вселенной не родилось бы столько гигантских и разнообразных структур, и не существовали бы мы.Вселенная не просто равномерно расширяется, но имеет внутри себя крошечные несовершенства плотности, которые с течением времени позволяют формировать планеты, звезды, галактики и скопления галактик. Добавление неоднородностей плотности поверх однородного фона — отправная точка для понимания того, как выглядит и работает наша Вселенная.Детали, которые появляются в современной космической паутине, определились гораздо раньше. «Зёрна» современных крупномасштабных структур были заложены там, в самой ранней Вселенной. Сегодняшние звезды, туманности и скопления галактик можно проследить до первых маленьких несовершенств плотности, возникших тогда, когда первые атомы впервые сформировались во Вселенной. Эта связь вызвана гравитацией и тем фактом, что по Общей теории относительности концентрация материи и энергии определяет кривизну пространства.Эти древние семена, хоть и плохо, но остаются видимы сегодня — в виде маленьких температурных несовершенств в космосе вокруг нас. Где-то космос чуть «теплее» (там больше материи), где-то чуть холоднее. Это так называемый космический микроволновой фон — остаточное сияние Большого взрыва, впервые обнаруженное в 1965 году. Температуры этого сияния находятся в пределе 2,72548 ± 0,00057 Kельвина, то есть это практически абсолютный ноль. Но оно всё-таки есть. Фоновое излучениеМы все живём на этом фоне. Просто он настолько слабый (ещё бы, 13,8 млрд лет прошло!), что заметить его могут только наши самые совершенные аппараты. А когда ученые впервые его засекли, то даже не поняли, что происходит: они думали, что у них барахлит оборудование. Но в общем да, если вас учили в школе, что в глубоком космосе — абсолютный ноль, то это неправда. Из-за всё еще остающегося после Большого взрыва излучения температура космоса составляет почти три Кельвина. Хотя она постепенно снижается, так что ещё через несколько миллиардов лет новым цивилизациям потребуются куда более мощные приборы, чтобы её обнаружить. А дальше — тайны начала Вселенной станут окончательно покрыты мраком.Но пока что наши устройства, если их точно настроить, могут наблюдать этот реликтовый фон, потому что свет должен пройти из дальних областей пространства, в которых он возникает, к «глазам» наблюдателя. А это означает, что:сверхплотные области с большим количеством материи и энергии, чем в среднем, будут казаться более холодными, поскольку свет должен «выбраться» из более крупного гравитационного потенциала;области с пониженной плотностью, с меньшим количеством материи и энергии, будут казаться более горячими, чем в среднем, поскольку свету будет проще дойти до нас;области средней плотности и гравитационного потенциала будут иметь среднюю температуру космического микроволнового фона.Эти температурные несовершенства, которые мы наблюдаем в остаточном сиянии Большого взрыва, пришли к нам из эпохи, которая наступила через 380 000 лет после «запуска» Вселенной — когда первичная плазма охладела настолько, что электроны и протоны смогли начать образовывать атомы водорода. Это событие впервые сделало Вселенную почти прозрачной для излучения — потому что свет больше не рассеивался, сталкиваясь с морем свободных электронов.К сожалению, более ранние этапы существования нашей Вселенной мы наблюдать не можем: там просто нечего было наблюдать. Но даже отпечаток Вселенной через 380 000 лет после её основания представляет собой достаточно большой набор данных, который можно анализировать.Когда мы видим горячую или холодную точку в реликтовом излучении, эта разница температур обычно соответствует области пониженной или повышенной плотности во время появления реликтового излучения через 380 000 лет после Большого взрыва. Это следствие эффекта Сакса-ВульфаОткуда вообще возникли эти несовершенства? Почему Вселенная не единообразна во всех направлениях? История тут совершенно разная, в зависимости от того, какого варианта «начала всего» вы придерживаетесь:Согласно «сингулярной» теории Большого взрыва, Вселенная просто «родилась» с исходным набором несовершенств. Потом эти несовершенства росли и развивались по законам гравитационного коллапса и взаимодействия частиц, в том числе взаимодействия между нормальной и темной материей.Если принять инфляционную теорию происхождения Вселенной, где горячий Большой взрыв возник только после какого-то периода космического расширения, тогда эти несовершенства посеяны квантовыми флуктуациями. То есть флуктуациями, возникающими даже в пустом пространстве из-за принципа неопределенности энергии и времени, присущего квантовой механике. То есть наша Вселенная не была случайно рождена «неравномерной»: если пространство и время появились до Взрыва, то ни в каком другом виде она и не могла существовать.Второй вариант объяснения дает нам важную зацепку. Если эта теория верна, то получается, квантовые флуктуации, существовавшие до Большого взрыва, каким-то образом отображены в нём. За прошедшие миллиарды лет эти маленькие отблески растянулись до гигантских масштабов за счет расширения Вселенной. А более поздние флуктуации растянулись уже поверх них.Отсюда идёт важный вывод. Если что-то существовало до взрыва, оно должно быть самым большим, самым «растянутым». В теории, даже больше горизонта самой нашей Вселенной — которая расширяется как результат того самого взрыва. Мы должны быть способны заметить результаты в масштабах, превышающих космический горизонт: так называемые флуктуации сверхгоризонта. Если они существуют — значит, сам Большой взрыв не мог быть началом всего.Квантовые флуктуации, возникающие во время инфляции, накладываются друг на друга, поэтому выявить более старые и более масштабные может быть очень непросто. Нужны очень точные приборы, результатам которых мы можем доверятьЕщё раз. В «сингулярной» картине Большого взрыва, где всё было сжато в одну точку и он был началом всего, результаты флуктуаций, которые мы ожидаем увидеть, будут ограничены скоростью света (+ расстоянием, на которое за это время успел расшириться космос). Если же до взрыва что-то существовало, то «мазки на картине», теоретически могут быть больше. Намного больше (если это «что-то» существовало ощутимое время и было достаточно крупным). Или всего на несколько процентов больше (если время и пространство до Большого взрыва было невелико).Это, конечно, было бы очень сложно заметить. Флуктуации, которые могли произойти за несколько сотен долей секунды до взрыва, уже растянуты до масштаба большего, чем наблюдаемая в настоящее время Вселенная. А более поздние флуктуации накладываются на более ранние, засоряя сигнал. Но мы хотя бы понимаем методику: если что-то существовало до Большого Взрыва, мы можем начать поиск сверхмасштабных флуктуаций, которых не должно было бы быть, если бы Вселенная началась с сингулярности.Остаточное свечение Большого взрыва, реликтовое излучение, имеет крошечные несовершенства: колебания температуры величиной в несколько сотен микрокельвинов. Эти флуктуации были вызваны комбинацией процессов, но в том числе и неоднородностьюВ общем, большой тест, который можно провести, состоит в том, чтобы исследовать Вселенную и искать либо наличие, либо отсутствие этих флуктуаций сверхгоризонта. Существует предел тому, как далеко мог пройти сигнал, который двигался со скоростью света. И нам нужно понять, когда он был испущен.Масштабы меньше горизонта Вселенной зависят от физики, которая возникла с момента начала горячего Большого взрыва.Масштабы, равные горизонту, являются верхним пределом того, на что могли повлиять физические сигналы с момента начала горячего Большого взрыва.Масштабы, превышающие горизонт, известные как масштабы сверхгоризонта, выходят за пределы того, что могло быть вызвано физическими сигналами, генерируемыми во время или после Большого взрыва.Изнутри нашей Вселенной заметить эти широкие «мазки» на нашем уровне технологий — достаточно сложно. Но, к счастью, наблюдение за температурой космического микроволнового фона — это не единственный способ получить информацию. Мы также можем посмотреть на поляризацию света от этого фона. Поляризация светаДальше будет очень научно, но вкратце смысл такой: мы смотрим на то же реликтовое излучение (другой информации нет), но не на его температуру, а на его поляризацию — насколько электромагнитные волны, дошедшие к нам с тех времен, структурированы в том или ином плане. Это позволяет говорить о структурах, существовавших там, где эти волны прошли.Когда свет проходит через Вселенную, он взаимодействует с материей внутри нее — в частности, с электронами. Если свет поляризуется радиально-симметричным образом, это пример поляризации вектора Е (электрического). Если свет поляризован по часовой стрелке или против часовой стрелки, то это пример поляризации вектора B (магнитного).И здесь можно провести корреляционный анализ: между поляризацией света, который мы ловим, и температурными флуктуациями космического микроволнового фона. Сопоставить их в тех же угловых масштабах. Это позволит нам отсечь лишний шум и заметить остаточные последствия самых больших флуктуаций. И понять, какой сценарий мы наблюдаем: «сингулярный Большой взрыв без инфляции» или «инфляционное состояние, которое и привело к горячему Большому взрыву».На этой карте показан сигнал поляризации реликтового излучения, полученный спутником Планка в 2015 годуКак их отличить, эти два сценария основания Вселенной, глядя на поляризацию, если супер-технически:Hidden textВ обоих случаях мы ожидаем увидеть субгоризонтные корреляции (как положительные, так и отрицательные) между поляризацией вектора Е в космическом микроволновом фоне и температурными флуктуациями в его пределах. Это вполне очевидно: если на пути света есть материя, в которой находятся электроны, то там будет и поляризация, и нехарактерная для остального фона температура.В обоих случаях мы ожидаем, что в масштабе космического горизонта (на данный момент соответствующего угловым масштабам около 1 градуса и мультипольному моменту около l = 200-220) эти корреляции будут равны нулю.Однако в масштабах сверхгоризонта сценарий «сингулярного Большого взрыва» будет иметь только один большой положительный «всплеск» корреляции между поляризацией Е-моды и температурными флуктуациями космического микроволнового фона — это тот момент, когда звезды начали формироваться в больших количествах и стали реионизировать межгалактическую среду. С другой стороны, сценарий «инфляционного Большого взрыва» обязан содержать этот всплеск, но также должен показать ряд отрицательных корреляций между поляризацией Е-моды и температурными флуктуациями в масштабах сверхгоризонта (в угловых масштабах между 1 и 5 градусами, мультипольные моменты от l = 30 до l = 200). Это продемонстрировало бы, что что-то существовало до взрыва и оставило следы, не зависящие от него. Характерные «мазки» в масштабах, даже превышающих размеры реликтового излучения.Эта публикация команды спутника WMAP 2003 года является самой первой научной статьей, в которой представлены доказательства сверхгоризонтных флуктуаций в спектре корреляции температуры и поляризации (так называемой «взаимной корреляции TE»). Точки — это реальные показатели корреляции. Тот факт, что слева от зеленой пунктирной линии (т.е. в масштабах сверхгоризонта) корреляция выходит отрицательной — сложно не заметить. Это значит, что помимо материи, образовавшейся после Большого взрыва, на поляризацию реликтового излучения влияет что-то ещеПо этому самому первому графику, опубликованному командой телескопа WMAP в 2003 году (ровно 20 лет назад!), видно то, что космологи называют «спектром взаимной корреляции TE»: корреляции между поляризацией E-моды и флуктуациями температуры космического микроволнового фона.Как мы можем видеть, в субгоризонтных масштабах (справа от зеленой линии) присутствуют как положительные, так и отрицательные корреляции. Но в сверхгоризонтных масштабах (слева от линии) отчетливо виден большой «провал» — значительная зона отрицательной корреляции. Это согласуется с прогнозом теории инфляции (сплошная линия). И категорически не согласуется с теорией сингулярности Большого взрыва (пунктирная линия).Конечно, это было 20 лет назад, и с тех пор наши технологии продвинулись вперед. Спутник WMAP был заменен спутником Планка, который превосходил его почти по всем параметрам. Он видел Вселенную в большем количестве диапазонов длин волн, мог опускаться до меньших угловых масштабов, лучше считывал нюансы температуры, включал в себя специальный поляриметрический прибор и чаще брал снимки неба, что еще больше уменьшало вероятность ошибок.И когда мы смотрим на окончательные (2018 года) данные кросс-корреляции TE от команды Планка, результаты захватывают дух. Всё предельно очевидно:Если кто-то хочет увидеть недвусмысленное свидетельство сверхгоризонтных флуктуаций, ему достаточно посмотреть на показатели «взаимной корреляции TE» (поляризации и температуры) от спутника Планка. В диапазоне сверхгоризонта (слева от зеленой линии) виден очень четкий, очень характерный «провал». После того, как в 2018 году ученые его увидели, доказательства в пользу существования сверхгоризонтных флуктуаций стали неопровержимы.ВыводыКак мы можем ясно видеть по данным спутников, не остается никаких сомнений в том, что во Вселенной точно существуют сверхгоризонтные флуктуации. А это значит, что неинфляционная сингулярная модель Большого взрыва, которая считалась общепринятой почти 100 лет, не согласуется со Вселенной, которую мы наблюдаем. Вместо этого мы видим, что горячему Большому взрыву должно было предшествовать инфляционное состояние. Которое, правда, длилось не очень долго — судя по размеру флуктуаций и степени их влияния на современный космос.Наша Вселенная существовала и до Большого взрыва, вероятно — краткую долю секунды. В ней, скорее всего, еще не было атомов, но уже происходили квантовые процессы, вызвавшие неравномерности распределения энергии. А уже после этого случился Взрыв.И русская, и английская Википедия сейчас довольно обтекаемо касаются этого момента. Так что у читателей, которые привыкли, что Большой взрыв = сингулярность, это мнение не нарушается. А зря.Есть и другие тесты на наличие «довзрывной» инфляции, которые можно было бы провести. Оценить масштабно-инвариантный спектр чисто адиабатических флуктуаций, проверить ограничение максимальной температуры горячего Большого взрыва, найти небольшое отклонение от идеальной плоскостности в космологической кривизне, проверить спектр «первобытных» гравитационных волн, постоянно доносящихся к нам с того времени. И так далее. Тем не менее тест на наличие флуктуаций сверхгоризонта достаточно прост и надежен. И уже проведен. Если остальные эксперименты когда-нибудь осуществят — то только для того, чтобы подтвердить уже известное: пространство и время существовали и до Большого взрыва.Это лучшая из имеющихся у нас картин того, как ведет себя вся Вселенная, где инфляция предшествует Большому взрыву и вызывает его.Как всё это выглядело, в каком формате оно существовало, как долго? Не ясно. Но по крайней мере это точно была уже наша Вселенная: в ней работали известные нам законы квантовой физики, и их последствия видны на звездном небе, если хорошо присмотреться.А дальше — пространство для новых открытий и новых теорий. Потому что теперь мы знаем, что Большой Взрыв, оказывается, не был началом всего.",Виртуальные и выделенные серверы в ДЦ в Москве,  Научно-популярное Системное администрированиеЧитальный залИнформационная безопасностьIT-инфраструктура,398.02
5,44 совета по Ansible: рекомендации и Best Practices,Southbridge,"2023-03-30, 09:57","Ansible — один из наиболее часто используемых программных инструментов с открытым исходным кодом для управления конфигурацией, предоставления программного обеспечения и развертывания приложений в облачных и локальных средах. В этой статье мы поделимся Practices по настройке Ansible, предложим интересные подходы для эффективной работы с внутренними компонентами продукта.Базовые Best PracticesВыбирайте YAML вместо JSON: Хотя Ansible позволяет использовать синтаксис JSON, с YAML читать файлы и проекты гораздо легче.Используйте одинаковые пробелы: Чтобы красиво разделить объекты и улучшить читаемость, оставьте пустую строку между блоками, задачами или другими компонентами.Используйте последовательную стратегию тегирования: Тегирование — это мощная функция в Ansible, поскольку она позволяет группировать задачи и детальнее ими управлять. Теги дают нам возможность добавлять тонкие элементы управления выполнением задач.Добавляйте комментарии: Если вы считаете, что это необходимо, не стесняйтесь использовать комментарии, объясняющие цель и причину возникновения задач, переменных и так далее.Используйте стратегию с последовательным именованием: Прежде, чем приступить к настройке своих проектов в Ansible, подумайте о применении последовательной стратегии именования для задач, плейбуков, переменных, ролей и модулей.Определите руководство по стилю: Следуйте букве руководства — оно поможет последовательно выполнять задачи. Если вы ищете вдохновение, посмотрите на это руководство по стилю от OpenShift.Будьте проще: Ansible предоставляет множество опций и расширенных возможностей, но это не значит, что мы должны использовать их все в один момент времени. Найдите те инструменты Ansible, которые подходят для вашего случая, и попытайтесь максимально упростите свой проект. Например, начните с простого плейбука и файла инвентаризации, а более сложные инструменты или рефакторинг добавьте позже.Храните свои проекты в системе контроля версий (VCS): Сохраняйте файлы Ansible в репозитории кода и регулярно фиксируйте новые изменения.Не храните конфиденциальные значения в обычном тексте: Для секретов и конфиденциальных значений используйте Ansible Vault для шифрования переменных и файлов и защиты любой конфиденциальной информации.Тестируйте проекты: Используйте инструменты типа Ansible Lint и добавляйте этапы тестирования в конвейеры CI/CD для ваших репозиториев Ansible. Для тестирования ролей Ansible рекомендуем взглянуть на Molecule. Для тестирования вводимых данных или проверки пользовательских выражений можно использовать модуль assert.Организуйте каталогиПосмотрите, как выглядит хорошо организованная структура каталогов Ansible:inventory/   production        # inventory file for production servers   staging          # inventory file for staging environment   testing          # inventory file for testing environment  group_vars/  group1.yml       # variables for particular groups  group2.yml host_vars/  host1.yml        # variables for particular systems  host2.yml  library/         # Store here any custom modules (optional) module_utils/       # Store here any custom module_utils to support modules (optional) filter_plugins/      # Store here any filter plugins (optional)  master.yml        # master playbook webservers.yml      # playbook for webserver tier dbservers.yml       # playbook for dbserver tier  roles/  example_role/        # this hierarchy represents a ""role""    tasks/      #      main.yml   # <-- tasks file can include smaller files if warranted    handlers/     #      main.yml   # <-- handlers file    templates/    # <-- files for use with the template resource      ntp.conf.j2  # <------- templates end in jinja2    files/      #      bar.txt    # <-- files for use with the copy resource      foo.sh    # <-- script files for use with the script resource    vars/       #      main.yml   # <-- variables associated with this role    defaults/     #      main.yml   # <-- default lower priority variables for this role    meta/       #      main.yml   # <-- role dependencies    library/     # roles can also include custom modules    module_utils/   # roles can also include custom module_utils    lookup_plugins/  # or other types of plugins, like lookup in this case   monitoring/       # same kind of structure as ""common"" was above, done for the monitoring roleBest Practices инвентаризации Best PracticesИспользуйте группы инвентаризации: Группируйте узлы на основе общих атрибутов, которые они могут разделять — расположение, цель, роли, среда.Делайте отдельную инвентаризацию для каждой среды: Определите отдельный файл инвентаризации для каждой среды — производственной, промежуточной, тестовой и так далее, чтобы изолировать их друг от друга и избежать ошибок, связанных с неправильным выбором среды.Проводите динамическую инвентаризацию: При работе с облачными провайдерами или быстро меняющимися средами ведение статических инвентаризаций может стать сложной задачей. Используйте динамическую группировку во время работы: Мы можем создавать динамические группы с помощью модуля `group_by` на основе заданного атрибута — к примеру, на основе их операционной системы — и выполнять различные задачи на каждом из них без определения таких групп в инвентаризации.- name: Gather facts from all hosts  hosts: all  tasks:   - name: Classify hosts depending on their OS distribution    group_by:     key: OS_{{ ansible_facts['distribution'] }}  # Only for the Ubuntu hosts - hosts: OS_Ubuntu  tasks:   - # tasks that only happen on Ubuntu go here   # Only for the CentOS hosts - hosts: OS_CentOS  tasks:   - # tasks that only happen on CentOS go hereBest Practices для плейбуков и сценариевВсегда указывайте статус задач: Чтобы сделать ваши задачи более понятными, задавайте параметр state, даже если это не требуется из-за значения по умолчанию.Размещайте каждый аргумент задачи в отдельной строке: Это помогает сделать файлы Ansible более удобными для чтения. Рассмотрим несколько примеров:Это рабочий, но плохо читаемый вариант:- name: Add the user {{ username }}  ansible.builtin.user: name={{ username }} state=present uid=999999 generate_ssh_key=yes  become: yesВместо этого вы можете использовать данный синтаксис: он улучшает читабельность и понятность задач и их аргументов:- name: Add the user {{ username }}  ansible.builtin.user:   name: ""{{ username }}""   state: present   uid: 999999   generate_ssh_key: yes  become: yesИспользуйте плейбуки верхнего уровня для оркестровки плейбуков нижнего уровня: Вы можете логически сгруппировать задачи, сценарии и роли в низкоуровневых плейбуках и использовать плейбуки верхнего уровня для требуемой вам оркестровки. Группируйте задачи с помощью блочного синтаксиса: Задачи, которые связаны друг с другом и имеют общие атрибуты или теги, могут быть сгруппированы с помощью функции blok. Еще одним преимуществом этой опции является более простой задач, находящихся в одном блоке.- name: Install, configure, and start an Nginx web server  block:   - name: Update and upgrade apt    ansible.builtin.apt:     update_cache: yes     cache_valid_time: 3600     upgrade: yes    - name: ""Install Nginx""    ansible.builtin.apt:     name: nginx     state: present    - name: Copy the Nginx configuration file to the host    template:     src: templates/nginx.conf.j2     dest: /etc/nginx/sites-available/default       - name: Create link to the new config to enable it    file:     dest: /etc/nginx/sites-enabled/default     src: /etc/nginx/sites-available/default     state: link    - name: Create Nginx directory    ansible.builtin.file:     path: /home/ubuntu/nginx     state: directory    - name: Copy index.html to the Nginx directory    copy:     src: files/index.html     dest: /home/ubuntu/nginx/index.html    notify: Restart the Nginx service  when: ansible_facts['distribution'] == 'Ubuntu'  tags: nginx  become: true  become_user: rootИспользуйте контроллеры для запущенных задач: Контроллеры позволяют выполнить задачу после внесенных изменений. Контроллер будет запущен, когда произойдут изменения в файле index.html из приведенного выше примера.handlers:  - name: Restart the Nginx service   service:    name: nginx    state: restarted   become: true   become_user: rootBest Practices для переменныхПеременные позволяют пользователям параметризовать различные компоненты Ansible и хранить значения, которые мы можем повторно использовать. Всегда задавайте значения по умолчанию для ваших переменных: Установите значения по умолчанию для всех групп в group_vars/all. Для каждой роли установите переменные по умолчанию в roles/<role_name>/defaults.main.yml.Используйте каталоги groups_vars и host_vars: Чтобы файл инвентаризации был максимально аккуратным и лаконичным,  устанавливайте переменные групп и хостов в каталогах groups_vars и host_vars.Ссылайтесь на роль в переменных в качестве префикса: Старайтесь быть четкими при определении имен переменных для ролей. nginx_port: 80 apache_port: 8080Best Practices для модулейХраните локальные модули рядом с плейбуками: Используйте каталог ./library каждого проекта Ansible для хранения соответствующих пользовательских модулей. Плейбуки, которые имеют каталог ./library относительно своего пути, могут напрямую ссылаться на любые модули внутри него.Не используйте модули command и shell: Рекомендуем использовать их только тогда, когда нет другого выбора. Вместо этого выбирайте специализированные модули, которые обеспечивают отказоустойчивость и необходимую обработку ошибок.Указывайте аргументы модуля, когда это имеет смысл: Во многих аргументах модулей значения по умолчанию могут быть опущены. Для удобства можно указать некоторые из этих аргументов, например, для определения статуса плейбука.Отдавайте предпочтение многозадачности в модуле, а не циклам: Наиболее эффективным способом определения списка однотипных задач типа установки пакетов является использование нескольких задач в одном модуле.- name: Install Docker dependencies  ansible.builtin.apt:   name:    - curl    - ca-certificates    - gnupg    - lsb-release   state: latestДокументируйте и тестируйте пользовательские модули: Каждый пользовательский модуль должен содержать примеры, записанные настройки и описание полученных ответов. Новые модули следует тщательно тестировать перед выпуском. Вы можете создать плейбуки для тестирования пользовательских модулей и проверки различных сценариев для тестов.Best Practices для ролейСледуйте структуре каталога ролей Ansible Galaxy: Используйте команду ansible-galaxy init <role_name> для создания стандартного каталога ролей.Сохраняйте назначение ролей: Каждая роль должна иметь отдельную ответственность и отдельную функциональность. Разделяйте роли на основе различных функциональных возможностей или технических областей задач.Ограничивайте зависимости между ролями: Избегая большого количества зависимостей в ваших ролях, вы поддерживать их слабосвязанными, разрабатывать их независимо друг от друга и использовать их без заморочек со сложными зависимостями между ними.Отдавайте предпочтение модулям import_role или include_role: Чтобы лучше контролировать порядок выполнения ролей и задач, используйте модули import_role или include_role, а не классические роли.Будьте осторожны в отношении Ansible Galaxy Roles: При загрузке и использовании содержимого и ролей из Galaxy проверяйте содержимое файлов и выбирайте роли от надежных авторов.Храните используемые роли Galaxy локально: Чтобы не зависеть от внешнего репозитория Ansible Galaxy, вы можете хранить любые роли из Galaxy в своих репозиториях кода и управлять ими как частью проекта.Best Practices для развертывания средыСначала протестируйте изменения в staging: Это отличный способ убедиться в том, что изменения приведут к ожидаемому результату, а не к новым проблемам.Ограничьте выполнение задач заданными узлами: Если вы хотите запустить плейбук на определенном хосте, вы можете использовать флаг --limit. Если вам нужно запустить только определенные задачи из плейбука на основе тегов, вы можете определить, какие теги будут выполняться, с помощью флага --tags.Проверьте, какие задачи будут запущены перед выполнением: Вы можете использовать флаг --list-tasks для подтверждения того, какие задачи будут запущены без их фактического выполнения. Вы можете использовать флаг --list-hosts: так вы убедитесь в том, на какие хосты повлияет плейбук, но при этом не запустить его.Убедитесь в том, что вы собрались менять, но при этом не запускайте обновления: Используйте флаг --check для прогнозирования изменений, которые могут произойти. Объедините его с флагом --diff, чтобы показать различия в измененных файлах.Начните с конкретной задачи: Используйте флаг --start-at-task, чтобы плейбук начал работать с выбранной вами задачи.Используйте Rolling Updates для контроля количества целевых машин: По умолчанию Ansible пытается запустить программу параллельно на всех хостах. Чтобы добиться непрерывных обновлений, вы можете использовать ключевое слово serial. Используя это ключевое слово, вы можете определить, на скольких хостах изменения могут выполняться параллельно.Управляйте стратегией выполнения (запуска) playbook: По умолчанию Ansible завершает выполнение каждой задачи на всех хостах перед переходом к следующей задаче. Если вы хотите выбрать другую стратегию выполнения, ознакомьтесь с этой документацией. От редакцииС инструментами Ansible мы подробно знакомимся на курсе DevOps Upgrade — интенсивном курсе для тех, кто хочет стать DevOps-инженером. Поток стартует с практическими заданиями и поддержкой от спикеров курса стартует уже 15 мая — узнать подробнее о программе и присоединиться к группе вы можете на нашем сайте. ",Обеспечиваем стабильную работу highload-проектов,  IT-инфраструктура DevOpsСистемное администрированиеКарьера в IT-индустрииПрограммирование,272.35
6,Файловая система BTRFS,OTUS,"2023-03-29, 17:03","Некоторое время назад мной была представлена статья, посвященная дисковой подсистеме ОС Linux и среди прочих в комментариях к данной статье предлагалось рассмотреть работу с кэшем в файловой системе BTRFS. В этой статье я предлагаю вернуться к теме файловых систем в Linux и для начала посмотреть что из себя представляет BTRFS, где применяется и как с ней лучше работать. Данная статья предназначена для администраторов Линукс, имеющих практический опыт администрирования данной ОС.Итак, файловая система BTRFS (B-Tree Filesystem) предназначена для работы в Unix-подобных операционных системах. Она была разработана компанией Oracle в 2007 году. BTRFS построена по принципу CoW (Copy on Write), то есть при чтении области данных используется общая копия, в случае изменения данных — создается новая копия. Данная технология используется для оптимизации многих процессов, происходящих в операционной системе. Немного о деревьяхВ BTRFS как и в других ФС все данные хранятся на диске по определенным адресам, которые в свою очередь сохранены в метаданных. Однако, здесь все данные организуются в B-деревья (те самые B-tree, которые присутствуют в названии ФС). Не вдаваясь в дебри математических наук, которыми многих из нас мучали в вузе, кратко поясню принцип поиска в таких деревьях.При поиске B-Tree мы должны выбирать пути из нескольких вариантов. То есть, если мы ищем в дереве например, значение 30, как представлено на картинке ниже, то при обходе мы сначала проверим ключ в корне, 13 меньше 30, значит нам надо перейти на правого потомка, 17<30, 24<30, значит снова переходим на правого потомка и здесь находим нужное значение. Какое все это имеет отношение к работе файловой системы? B-Tree  в отличии от двоичных деревьев позволяет хранить много ключей в одном узле и при этом может ссылаться на несколько дочерних узлов. Это значительно уменьшает высоту дерева и, соответственно, обеспечивает более быстрый доступ к диску. Но вернемся к BTRFS.Основные характеристикиПрежде всего, как положено при описании какой-либо технологии или решения, приведу основные характеристики BTRFS. Максимальный размер файла в данной ФС может составлять 2^64 байт или 16 экзабайт. При этом в BTRFS также реализована компактная упаковка небольших файлов и индексированные каталоги с экономией места. Для сжатия используются алгоритмы ZLIB, LZO, ZSTD, а также эвристика. Контрольные суммы для данных и метаданных вычисляются с помощью алгоритмов crc32c, xxhash, sha256, blake2b.Ну а кроме этого, в BTRFS есть также динамическое распределение индексов, моментальные снимки с возможностью записи, снимки только для чтения и вложенные тома (отдельные корни внутренней файловой системы). Далее мы более подробно поговорим об этих технологиях и начнем с работы со снимками.Снимки в файловой системеПри работе с файлами, в частности, при операции перезаписи данных, они по факту не перезаписываются, а та часть данных, которая подверглась модификации копируется на новое место.  Затем просто обновляются метаданные о расположении изменившейся информации. Благодаря такому решению мы можем создавать мгновенные снимки файловой системы, которые не занимают места на диске, пока не было внесено много изменений. Ну а если старый блок больше не нужен, потому что он не является частью какого-либо снимка, то мы можем его автоматически удалить.Работа с дискамиКак мы уже упомянули ранее BTRFS может работать с файлами до 16 Экзабайт. Хотя текущая реализация VFS Linux (виртуальной файловой системы,  т.е. промежуточного слоя абстракции) имеет ограничение ядра до 8 Экзабайт. Но даже это уже огромный объем для работы с которым нужны соответствующие носители и BTRFS умеет эффективно работать с такими носителями. Большинство файловых систем используют диск целиком, от начала и до конца для записи своей структуры. Но BTRFS работает с дисками по-другому: независимо от размеров диска, мы делим его на блоки по 1 Гб для данных и 256 Мб для метаданных. Из этих блоков формируются группы, причем, каждая из которых может храниться на разных устройствах. При этом, количество таких блоков в группе может зависеть от уровня RAID для данной группы.  Для управления блоками и группами используется специальное средство – менеджер томов, который уже интегрирован в файловую систему.И еще одна небольшая плюшка. BTRFS при работе с небольшими файлами (по умолчанию до 8К) хранит их непосредственно в метаданных, тем самым снижая накладные расходы и уменьшая фрагментацию диска. Таким образом, наличие большого количества маленьких файлов, как минимум, не приведет к существенной просадке производительности.Думаю, теории для этой статьи достаточно и сейчас самое время перейти к практике, а именно создать файловый раздел. В своем примере я буду по традиции использовать Ubuntu 22.04, однако другие современные дистрибутивы также должны поддерживать BTRFSРазворачиваем BTRFSТрадиционно, процесс установки какого-либо ПО под Linux начинается с обновления пакетов:sudo apt updateДалее в случае с Ubuntu 22.04 у меня поддержка ФС уже есть. Но в случае ее отсутствия необходимо было бы выполнить:sudo apt install btrfs-progs -yДалее нам потребуется неразмеченный диск. Посмотрим что у нас есть с помощью команды:sudo lsblk -e7В моем примере я буду работать с sdb размером 10 Гб.Так как мы будем мучать sdb, то укажем его в параметрах утилиты cfdisk:sudo cfdisk /dev/sdbПосле запуска утилиты выбираем gpt.Далее все достаточно стандартно: выбираем Free space. Так как я планирую использовать весь диск, то соответственно указываем использование всех 10 G. Если у вас планируется использовать только часть дискового пространства, тогда необходимо указать нужный размер. При этом можно использовать следующие сокращения для единиц измерения: M – мегабайты, G – гигабайты, T – терабайты.Для сохранения изменений не забудьте нажать Write.Теперь нам необходимо отформатировать созданный раздел в BTRFS.sudo mkfs.btrfs -L data /dev/sdbВ результате мы получили полную информацию об отформатированном диске. Теперь подмонтируем BTRFS раздел. Для этого сначала создаем точку монтирования. В моем случае это каталог /btrfs. А затем подмонтируем sdb к этому разделу.sudo mkdir -v /btrfssudo mount /dev/sdb /btrfsИ для того, чтобы убедиться в корректности выполненных операций, воспользуемся уже знакомой нам командой:sudo lsblk -e7Статистика использованияПоговорим немного о том, как можно смотреть различную статистику использования BTRFS дисков. Прежде всего воспользуемся командой:sudo btrfs filesystem usage /dataВывод команды содержит различные значения. Посмотрим что означает каждое из них. В первой строке у нас идет общий размер диска – 10 Гб. Далее мы видим объем дискового пространства, зарезервированного для хранения данных и еще неиспользуемого пространства, которого естественно намного больше, так как пока на диск записано немного данных – сколько именно мы видим из значения поля Used. Отрадно, что значение Device missing равно 0.Далее указаны методы (single или DUMP), которые используются для выделения дискового пространства для данных, метаданных и системных данных. При использовании single ФС хранит только одну копию данных, никакой дупликации не используется. Но при использовании DUP файловая система Btrfs выделит для одних и тех же данных дисковое пространство в разных частях файловой системы. Таким образом, в файловой системе будет храниться несколько копий (обычно две) одних и тех же данных.Как можно видеть из рисунка выше, обычные данные у нас распределены в single режиме, а вот метаданные и системные данные используют DUP.ЗаключениеВ этой статье мы начали рассмотрение файловой системы BTRFS. Поговорили об основных преимуществах этой ФС и рассмотрели создание раздела под управлением BTRFS. В заключении хотелось бы заметить, что в сети можно встретить негативные отзывы об использовании данной ФС. Однако, все эти отзывы датированы началом 2010-х годов, когда система еще не была стабильна и могли происходить сбои. Но сейчас эта ФС поддерживается многими операционными системами, ее спецификация уже много лет не изменяется и ее можно использовать без опасения потерять свои данные.В следующей статье мы продолжим рассмотрение BTRFS, и в частности поговорим об использовании нескольких дисков и создании отказоустойчивых конфигураций.Также я хочу порекомендовать вам бесплатный урок от моих коллег из OTUS, которые расскажут, как можно собрать кастомную версию Nginx из исходников. Вы добавите нестандартные модули и библиотеки: модуль brotli, поддержку HTTP/3, библиотеку BogingSSL, RTMP-модуль. А также подготовите окружение и соберёте deb-пакет для установки в систему.Зарегистрироваться на бесплатный урок",Цифровые навыки от ведущих экспертов,  Программирование JavaМашинное обучениеТестирование веб-сервисовPython,832.56
7,Миграция PostgreSQL с DBaaS на дроплет Digital Ocean,OTUS,"2023-03-29, 16:03","Недавно один из наших клиентов обратился к нам с одной интересной задачей: ему нужно было перенести весь свой кластер PostgreSQL с DBaaS (Database as a Service) на дроплет в рамках DigitalOcean. Причиной их перехода с DBaaS на дроплеты была их более низкая стоимость. Эта задача оказалась довольно сложной, поскольку в документации DigitalOcean четко сказано, что “в настоящее время мы не поддерживаем миграцию баз данных из одних кластеров DigitalOcean в другие кластеры в рамках DigitalOcean”.Короче говоря, нам нужно было переносить базу данных своими силами, и мы предоставили клиенту два варианта решения этой задачи:pg_dumpЛогическая репликацияМетод с pg_dump предполагает определенный период простоя, так как мы должны создать дамп, а затем восстановить его на новом сервере. Логическая репликация же оставляет исходную базу данных в рабочем состоянии пока данные копируются в новую базу данных. Как только мы достигнем желаемого состояния, мы можем переключиться на новую базу данных.Для миграции с помощью логической репликации все таблицы, которые необходимо реплицировать, должны иметь первичный или уникальный ключ.Предварительные требования для миграцииЧтобы перенести существующую базу данных в кластер базы данных DigitalOcean, нам необходимо убедиться, что в исходной базе данных включена логическая репликация, получить учетные данные для подключения к исходной базы данных и отключить или обновить любые файрволы между базами данных.Получить Root-права: Для подготовки базы данных к миграции и для проведения самой миграции нам нужны root-права в исходной базе данных.Сделать базу данных общедоступной: Для миграции базы данных имя хоста или IP-адрес исходной базы данных должны быть доступны из публичного интернета. Информация о публичном подключении к базам данных DigitalOcean находится в разделе “Connection Details” на панели управления базой данных.Разрешить удаленные подключения: Во-первых, убедитесь, что база данных разрешает все удаленные подключения. Это определяется переменной базы данных listen_addresses, которая разрешает все удаленные подключения, если ее значение равно. Чтобы проверить ее текущее значение, выполните в терминале PostgreSQL (psql) следующий запрос:SHOW listen_addresses; If enabled, the command line returns: listen_addresses ----------- * (1 row)Если ваш результат будет другим, вы можете разрешить удаленные подключения в вашей базе данных, выполнив следующий запрос:ALTER SYSTEM SET listen_addresses = '*';Мы также должны изменить ваше локальное IPv4-соединение, чтобы разрешить все входящие IP-адреса. Для этого вам нужно найти файл конфигурации pg_hba.conf с помощью следующего запросом:SHOW hba_file;Откройте pg_hba.conf в текстовом редакторе по вашему выбору, например, nano: nano pg_hba.confВ разделе “IPv4 local connections” найдите и замените IP-адрес на 0.0.0.0/0, что разрешат все IPv4-адреса:# TYPE DATABASE USER ADDRESS METHOD  # IPv4 local connections: host all all 0.0.0.0/0 md5 # IPv6 local connections: host all all ::/0 md5Включение логической репликацииУ большинства поставщиков облачных баз данных логическая репликация включена по умолчанию. Логическая репликация может быть не включена, если вы переносите базу данных с локального сервера. Если ваша база данных не подготовлена для логической репликации, то процесс миграции не будет работать, поскольку база данных может перемещать только ваши схемы, а не сами данные.Чтобы убедиться, что логическая репликация включена, выполните следующий запрос в терминале PostgreSQL (psql):show wal_level; If enabled, the output returns: wal_level ----------- logical (1 row) If the output is different, enable logical replication in your database by setting wal_level to logical: ALTER SYSTEM SET wal_level = logical;Изменение максимального количества слотов репликацииПосле включения логической репликации нам нужно убедиться, что значение max_replication_slots вашей базы данных равно или превышает количество баз данных на вашем PostgreSQL сервере. Чтобы проверить текущее значение, выполните следующий запрос в терминале PostgreSQL (psql):show max_replication_slots;Вывод будет выглядеть следующим образом:max_replication_slots ----------- (1 row)Если это значение меньше, чем количество баз данных на нашем PostgreSQL сервере, измените его, выполнив следующий запрос, где use_your_number — это количество баз данных на нашем сервере:ALTER SYSTEM SET max_replication_slots = use_your_number;И перезагрузите сервер.Проблемы, с которыми мы можем столкнуться во время миграцииКогда мы реализуем логическую репликацию без первичного ключа, мы можем столкнуться с некоторыми проблемами. Существует два разных метода реализации логической репликации без столбца с первичным ключом, один из которых — с использованием уникального ключа.Этот метод реализуется с помощью того же самого набора шагов, который мы собираемся здесь выполнить. Его технические аспекты также аналогичны. Просто вместо первичного ключа обновления будут происходить по уникальному ключу.ПредостереженияОн не поддерживает DELETE/UPDATE без репликационного идентификатора.Уникальный индекс нельзя использовать с репликационным идентификатором, если разрешены NULL-значения.Используется REPLICA IDENTITY FULL.Если для репликационного идентификатора не найден подходящий индекс, мы можем установить для него значение FULL. В этом случае все столбцы таблицы коллективно выступают в роли первичного ключа.Из-за дополнительного логирования создается огромное количество WAL.Этот метод может быть медленнее, чем традиционный.Что следует учитыватьИ так, нам нужно установить репликационный идентификатор FULL для таблиц, которые переносятся логически только по UNIQUE ключу, иначе DELETE/UPDATE не будет поддерживаться.После того, как данные из форка DBaaS будут синхронизированы на новую виртуальную машину на дроплете, нам нужно выполнить методы pg_dump и pg_restore для последовательностей. У вас может возникнуть вопрос: зачем нам дамп последовательности и почему мы не можем реплицировать ее с помощью логической репликации?Логическая репликация предназначена отслеживания изменений WAL и информирования подписчиков о текущих состояниях и значениях. Было бы довольно противоречиво реплицировать последовательность, потому что текущее значение последовательности не равно значению, хранящемуся в WAL. Чтобы компенсировать это, документация PostgreSQL предлагает вручную скопировать значения последовательности или использовать для копирования такую ​​утилиту, как pg_dump.Сделайте дамп последовательностей из форка БД DBaaSОстановите форк БД DBaaSВосстановите последовательности на новом дроплетеОтключите логические подпискиНиже приведен краткий обзор того, что было сделано для миграции среды:Исходный кластер: DBasS Digital Ocean Место назначения: дроплеты Digital OceanПроцесс:Клиент выбрал миграцию посредством логической репликации, чтобы сократить время простоя.На целевой виртуальной машине мы установили дистрибутив Percona для PostgreSQL 13.7.Перенесли в место назначения роли из исходного кластера, т.е. DBasS.Сформировали список таблиц, у которых нет первичного ключа, и проинформировал их.Для некоторых таблиц клиент добавил первичный ключ, а для остальных таблиц сформировал уникальный ключ.Установили на виртуальную машину расширения, которые были в исходном кластере.Сформировали дамп схемы из исходного кластера, т.е. DBasS.Восстановили ​​схему на месте назначения, т.е. на дроплетых.Скорректировали в исходном кластере и месте назначения параметры, связанные с логической репликацией, такие как max_replication_slots, max_logical_replication_workers и max_wal_senders.Настроили логическую репликацию, создав публикацию и подписку между исходным кластером и местом назначения.Как только место назначения было синхронизировано, отключили подписчиков.Сформировали дамп последовательностей из исходного кластера и восстановили их в месте назначения.Скорректировали файлы listen_address, pg_hba на месте назначения.Сбросили подписчиков на месте назначения.ЗаключениеКак мы все знаем, PostgreSQL — это объектно-реляционная система управления базами данных с открытым исходным кодом, созданная с упором на расширяемость, скорость и целостность данных. Ее поддержка параллелизма делает ее полностью совместимой с ACID. Мы смогли реализовать миграцию данных клиентов с DBasS на дроплеты, используя одну из замечательных фич PostgreSQL, то есть логическую репликацию. Мы также смогли сформировать дамп последовательностей из исходного кластера и восстановить их на месте назначения.В заключение статьи приглашаем всех желающих на открытое занятие «Автоматизация развертывания на кластера PostgreSQL на базе Patroni в Kubernetes», которое пройдет в рамках онлайн-курса ""PostgreSQL Cloud Solutions"".На этом открытом уроке будет разыграна книга руководителя курса Евгения Аристова — «PostgreSQL 14. Оптимизация, Kubernetes, кластера, облака».Регистрация на открытый урок",Цифровые навыки от ведущих экспертов,  Программирование JavaМашинное обучениеТестирование веб-сервисовPython,832.56
